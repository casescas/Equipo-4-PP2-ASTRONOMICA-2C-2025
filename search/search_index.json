{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\u2601\ufe0f\ud83d\ude80 Proyecto Cielo R\u00edo Grande \u2013 Equipo 4 \u00b7 PP2 Astron\u00f3mica 2C 2025","text":"<p>Proyecto de Ciencia de Datos e Inteligencia Artificial aplicado al an\u00e1lisis de la cobertura nubosa en R\u00edo Grande (Tierra del Fuego, Argentina).</p>"},{"location":"#descripcion-general","title":"\ud83d\udef0\ufe0f Descripci\u00f3n general","text":"<p>Este repositorio contiene el desarrollo completo del proyecto Cielo R\u00edo Grande, una aplicaci\u00f3n que utiliza t\u00e9cnicas de inteligencia artificial y visi\u00f3n por computadora para analizar im\u00e1genes capturadas por la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande (EARG), clasificando autom\u00e1ticamente el nivel de nubosidad.</p> <p>El proyecto forma parte de la materia Pr\u00e1cticas Profesionalizantes II (Astron\u00f3mica) de la Tecnicatura Superior de Ciencia de Datos e IA del Polit\u00e9cnico Malvinas Argentinas, y busca aplicar de manera pr\u00e1ctica los conocimientos adquiridos en la tecnicatura, desde el procesamiento de datos y entrenamiento del modelo hasta la evaluaci\u00f3n de resultados y su visualizaci\u00f3n t\u00e9cnica.</p>"},{"location":"#equipo","title":"\ud83d\udc65 Equipo","text":"<ul> <li>Carmueda, Pablo  </li> <li>Estrada, Diego  </li> <li>Isa, Facundo  </li> <li>Gonz\u00e1lez Sardi, Iara  </li> <li>Quinteros, Nicol\u00e1s  </li> </ul>"},{"location":"#objetivo-general","title":"\ud83c\udfaf Objetivo General","text":"<p>Desarrollar una aplicaci\u00f3n capaz de clasificar autom\u00e1ticamente el tipo de cielo (seg\u00fan el sistema OCTAS) a partir de im\u00e1genes capturadas por c\u00e1maras locales, utilizando un modelo de aprendizaje profundo (EfficientNet-B0) y desplegando los resultados en un dashboard interactivo.</p>"},{"location":"#componentes-principales","title":"\u2699\ufe0f Componentes Principales","text":"<ul> <li>Backend (FastAPI): gestiona el modelo de clasificaci\u00f3n, expone endpoints y registra predicciones en una base de datos SQLite.  </li> <li>Frontend (React + Recharts): muestra el historial de predicciones, gr\u00e1ficos de evoluci\u00f3n y permite exportar reportes en PDF.  </li> <li>Modelo de IA: red neuronal EfficientNet-B0 entrenada para clasificar im\u00e1genes seg\u00fan categor\u00edas de cobertura nubosa.  </li> <li>Pipeline de datos: procesos de backfill o ejecuciones en tiempo real y almacenamiento estructurado de resultados.  </li> <li>Documentaci\u00f3n: sitio generado con MkDocs que centraliza manuales t\u00e9cnicos, gu\u00edas y documentaci\u00f3n del c\u00f3digo.</li> </ul>"},{"location":"#estructura-del-repositorio","title":"\ud83d\udcc1 Estructura del Repositorio","text":"<pre><code>Equipo-4-PP2-ASTRONOMICA-2C-2025/\n\u251c\u2500\u2500 01.Data/\n\u251c\u2500\u2500 02.Notebooks/\n\u251c\u2500\u2500 03.SRC/\n\u251c\u2500\u2500 04.Reports/\n\u251c\u2500\u2500 05.Models/\n\u251c\u2500\u2500 06.Docs/\n\u251c\u2500\u2500 cielo-rio-grande/\n\u2502   \u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 frontend/\n\u2502   \u2514\u2500\u2500 docs/\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 mkdocs.yml\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 requirements.txt\n</code></pre>"},{"location":"#requisitos","title":"\ud83e\udde9 Requisitos","text":"<ul> <li>Python 3.12+</li> <li>Node.js 18+ y npm</li> <li>Git</li> <li>(Opcional) CUDA/cuDNN si se utiliza GPU para PyTorch</li> </ul>"},{"location":"#modelo-y-entrenamiento","title":"\ud83d\udd2c Modelo y Entrenamiento","text":"<p>El sistema utiliza EfficientNet-B0, seleccionado por su equilibrio entre precisi\u00f3n y eficiencia computacional. Fue entrenado en PyTorch con fine-tuning completo sobre im\u00e1genes clasificadas seg\u00fan la escala OCTAS (0\u20138).</p> Dataset Accuracy Loss Entrenamiento 74.9 % 0.135 Validaci\u00f3n 67.6 % 0.271 <p>El entrenamiento se detuvo en la \u00e9poca 80 mediante Early Stopping, mostrando ligera tendencia al sobreajuste pero desempe\u00f1o estable en clases extremas (0 y 8).</p>"},{"location":"#flujo-de-datos-y-backfill","title":"\ud83d\udd01 Flujo de Datos y Backfill","text":"<p>El pipeline procesa im\u00e1genes capturadas por la EARG cada 10 minutos mediante un scheduler APScheduler.</p> <p>Pasos principales: 1. Obtiene de la imagen (<code>utils.image_utils</code>) 2. Clasificaci\u00f3n con <code>predict_octas()</code> 3. Registro en SQLite (<code>data/registros-octas.db</code>)</p> <p>Ejemplo de salida:</p> <pre><code>\ud83d\udcca Backfill \u2192 total = 864 | nuevos = 830 | duplicados = 28 | fallidos = 6\n</code></pre>"},{"location":"#endpoints-api","title":"\ud83c\udf10 Endpoints API","text":"Endpoint M\u00e9todo Descripci\u00f3n <code>/octas</code> GET \u00daltima predicci\u00f3n registrada <code>/historial</code> GET Registros hist\u00f3ricos filtrables por fecha <code>/imagen</code> GET \u00daltima imagen del cielo disponible <code>/satellite</code> GET Imagen satelital de nubosidad (OpenWeatherMap) <code>/clima</code> GET Datos meteorol\u00f3gicos actuales"},{"location":"#conclusiones","title":"\ud83d\udcc8 Conclusiones","text":"<p>El proyecto Cielo R\u00edo Grande consolida un sistema completo para el an\u00e1lisis automatizado de la nubosidad local mediante t\u00e9cnicas de inteligencia artificial y procesamiento de im\u00e1genes. El modelo EfficientNet-B0 alcanz\u00f3 un rendimiento s\u00f3lido, especialmente en los extremos de la escala OCTAS, confirmando la viabilidad de aplicar deep learning en entornos con recursos limitados.</p> <p>La arquitectura implementada \u2014modelo de IA, backend FastAPI, frontend React y pipeline automatizado\u2014 posibilita tanto el an\u00e1lisis hist\u00f3rico como la predicci\u00f3n en tiempo real, aportando valor a la observaci\u00f3n astron\u00f3mica local.</p> <p>Desarrollado por el Equipo 4 \u2013 PP2 Astron\u00f3mica (2C 2025) para la Tecnicatura Superior en Ciencia de Datos e Inteligencia Artificial del Polit\u00e9cnico Malvinas Argentinas, en colaboraci\u00f3n con la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande (EARG).</p> <p></p>"},{"location":"API_Flujo_Backfill/","title":"\ud83c\udf24\ufe0f APP Cielo R\u00edo Grande: API, Flujo y Backfill","text":""},{"location":"API_Flujo_Backfill/#flujo-general","title":"Flujo general","text":"<p>El sistema procesa im\u00e1genes del cielo capturadas peri\u00f3dicamente por la c\u00e1mara instalada en el observatorio.</p> <p>Cada imagen pasa por un pipeline automatizado que se ejecuta cada 10 minutos y realiza tres tareas principales:</p> <ol> <li> <p>Obtiene la nueva imagen desde la fuente configurada (IMG_URL_BASE).</p> </li> <li> <p>Procesa la imagen con el modelo de clasificaci\u00f3n de nubes (predict_octas).</p> </li> <li> <p>Almacena el resultado en la base de datos local (registros-octas.db).</p> </li> </ol> <p>\ud83d\udca1 El flujo autom\u00e1tico (trigger) se ejecuta cada 10 minutos mediante APScheduler, mientras que el backfill se utiliza de manera eventual para reconstruir per\u00edodos pasados.</p> <p>El scheduler (definido en <code>jobs/scheduler.py</code>) ejecuta el pipeline de forma continua, garantizando la actualizaci\u00f3n de los datos en tiempo real.</p> <p>Cada ejecuci\u00f3n genera una nueva predicci\u00f3n de cobertura nubosa (en octas) junto con su nivel de confianza y categor\u00eda, lo que permite alimentar el dashboard anal\u00edtico con informaci\u00f3n actualizada y consistente.</p> <p>La arquitectura se apoya en los siguientes m\u00f3dulos:</p> <ul> <li> <p><code>utils.image_utils</code>: construye la URL de cada imagen en base al timestamp.</p> </li> <li> <p><code>services.clouds_service</code>: gestiona las funciones de predicciones y de obtenci\u00f3n de ellas.</p> </li> <li> <p><code>data/registros-octas.db</code>: almacena los registros hist\u00f3ricos y evita duplicados mediante claves \u00fanicas.</p> </li> <li> <p><code>jobs/scheduler.py</code>: coordina las ejecuciones peri\u00f3dicas del pipeline con <code>APScheduler</code>.</p> </li> </ul>"},{"location":"API_Flujo_Backfill/#modos-de-funcionamiento","title":"\ud83e\udde9 Modos de funcionamiento","text":"<p>El sistema opera en dos modos complementarios:</p> Modo Descripci\u00f3n Frecuencia Trigger (autom\u00e1tico) Obtiene la \u00faltima imagen disponible cada 10 minutos, la procesa con el modelo y guarda el resultado. Permanente Backfill (hist\u00f3rico) Recorre un rango de fechas pasado y obtiene las im\u00e1genes correspondientes para generar el registro hist\u00f3rico. Eventual / bajo demanda"},{"location":"API_Flujo_Backfill/#backfill-backfillpy","title":"Backfill (<code>backfill.py</code>)","text":"<p>El script <code>backfill.py</code> permite procesar im\u00e1genes hist\u00f3ricas dentro de un rango de fechas espec\u00edfico, ejecutando el mismo flujo del pipeline principal, pero de manera batch (no en tiempo real).</p> <p>Esto resulta \u00fatil para reconstruir per\u00edodos pasados o completar datos faltantes en la base que tambi\u00e9n ser\u00e1n utilizados por el dashboard.</p>"},{"location":"API_Flujo_Backfill/#funcionamiento","title":"Funcionamiento","text":"<p>El backfill recorre el rango temporal definido por los argumentos <code>--desde</code> y <code>--hasta</code>, procesando im\u00e1genes en intervalos de una hora.</p> <p>Dentro de cada hora se obtienen 6 im\u00e1genes fijas, correspondientes a los minutos v\u00e1lidos definidos en la constante:</p> <p>MINUTOS_VALIDOS \\= [2, 12, 22, 32, 42, 52]</p> <p>Por cada imagen:</p> <ol> <li> <p>Se genera la URL mediante <code>image_url(IMG_URL_BASE, intento, minuto, with_year_dir=True)</code>.</p> </li> <li> <p>Se obtiene la imagen con una sesi\u00f3n HTTP configurada con reintentos autom\u00e1ticos (<code>_new_session()</code> usa <code>Retry</code> y <code>HTTPAdapter</code>).</p> </li> <li> <p>Se clasifica la imagen con <code>predict_octas(resp.content)</code>.</p> </li> <li> <p>Se guarda el resultado con <code>save_prediction(data)</code>, que devuelve <code>True</code> si fue insertado o <code>False</code> si ya exist\u00eda.</p> </li> </ol> <p>La ejecuci\u00f3n contabiliza los resultados y muestra un resumen al finalizar.</p>"},{"location":"API_Flujo_Backfill/#ejemplo-de-ejecucion","title":"Ejemplo de ejecuci\u00f3n","text":"<p><code>python -m backfill --desde \"2025-01-01T00:00\" --hasta \"2025-01-31T23:59\"</code></p> <p>Durante la ejecuci\u00f3n se mostrar\u00e1 el progreso y, al finalizar, un resumen con el total de im\u00e1genes procesadas:</p> <p><code>\ud83d\udcca Backfill \u2192 total=864 | nuevos=830 | duplicados=28 | fallidos=6</code></p>"},{"location":"API_Flujo_Backfill/#estructura-de-carpetas-del-proveedor","title":"Estructura de carpetas del proveedor","text":"<p>El servidor de im\u00e1genes expone dos esquemas de ruta:</p> <p>Actual (sin subcarpeta por a\u00f1o)  Archivos recientes disponibles en la ra\u00edz del <code>IMG_URL_BASE</code>.</p> <p><code>{IMG_URL_BASE}/{YYYY}-{MM}{DD}{HH}{MM}.jpg</code></p> <ol> <li>Ej.: <code>.../2025-09010002.jpg</code></li> </ol> <p>Hist\u00f3rico (con subcarpeta por a\u00f1o)  A\u00f1os previos se sirven dentro de una carpeta por a\u00f1o.</p> <p><code>{IMG_URL_BASE}/{YYYY}/{YYYY}-{MM}{DD}{HH}{MM}.jpg</code></p> <p>Ej.: <code>.../2024/2024-09010002.jpg</code></p> <p>Por eso, cuando hacemos backfill sobre 2024 (u otros a\u00f1os anteriores), hay que incluir la carpeta del a\u00f1o en la URL.</p>"},{"location":"API_Flujo_Backfill/#como-lo-maneja-el-codigo","title":"C\u00f3mo lo maneja el c\u00f3digo","text":"<p>El helper <code>image_url(...)</code> ya admite este comportamiento mediante el par\u00e1metro <code>with_year_dir: bool</code>:</p> <ul> <li> <p>Pipeline online (<code>jobs/tasks.py</code>): <code>with_year_dir=False</code>    (obtiene de im\u00e1genes recientes en la ra\u00edz).</p> </li> <li> <p>Backfill (<code>backfill.py</code>): <code>with_year_dir=True</code>    (obtiene de hist\u00f3rico, incluyendo la carpeta de a\u00f1o).</p> </li> </ul> <p>Ejemplo en <code>backfill.py</code> :</p> <p><code>url_imagen = image_url(IMG_URL_BASE, intento, minuto, with_year_dir=True)</code></p>"},{"location":"API_Flujo_Backfill/#validaciones-y-tolerancia-a-fallos","title":"Validaciones y tolerancia a fallos","text":"<ul> <li> <p>Si <code>--hasta</code> es menor que <code>--desde</code>, el script finaliza con un mensaje de error.</p> </li> <li> <p>Los errores de red o im\u00e1genes no disponibles se contabilizan como fallidos (<code>miss</code>).</p> </li> <li> <p>La l\u00f3gica es idempotente: no duplica registros ya existentes en la base.</p> </li> <li> <p>Cada intento tiene un tiempo de espera m\u00e1ximo (<code>timeout=10</code>) y dos reintentos configurados (<code>Retry(total=2)</code>).</p> </li> </ul> <p>Variables y funciones principales</p> Variable / funci\u00f3n Descripci\u00f3n Tipo MINUTOS_VALIDOS Lista de minutos fijos por hora (6 im\u00e1genes). Constante _new_session() Crea la sesi\u00f3n HTTP con pol\u00edtica de reintentos. Interna backfill(desde, hasta) Ejecuta el recorrido temporal y procesamiento. P\u00fablica image_url() Construye la URL de cada imagen seg\u00fan fecha y minuto. Utilidad predict_octas() Ejecuta el modelo de clasificaci\u00f3n y devuelve el resultado. Servicio save_prediction() Guarda el registro en la base o lo omite si ya existe. Servicio <p>Consideraciones Finales: </p> <p>El sistema Cielo R\u00edo Grande combina un flujo continuo de actualizaci\u00f3n autom\u00e1tica con un mecanismo hist\u00f3rico flexible (backfill).</p> <p>Esta arquitectura permite mantener un registro completo y consistente de la nubosidad, tanto actual como pasada, garantizando datos confiables para el an\u00e1lisis y la visualizaci\u00f3n en el dashboard.</p> <p>\ud83d\udd0c Endpoints de la API</p> <p>El sistema expone una serie de endpoints implementados en FastAPI, que permiten consultar los resultados generados por el pipeline y complementar la informaci\u00f3n visualizada en el dashboard.</p> <p>Todos los endpoints est\u00e1n definidos dentro de la carpeta <code>backend/routers/</code>.</p>"},{"location":"API_Flujo_Backfill/#octas","title":"<code>/octas</code>","text":"<p>Devuelve la \u00faltima predicci\u00f3n registrada en la base de datos, incluyendo la cobertura nubosa en octas, el tipo de cielo, el nivel de confianza y la URL de la imagen procesada.</p> <p>Es el punto de acceso principal para el dashboard en tiempo real.</p>"},{"location":"API_Flujo_Backfill/#historial","title":"<code>/historial</code>","text":"<p>Permite consultar el registro hist\u00f3rico de predicciones dentro de un rango de fechas opcional (<code>desde</code> y <code>hasta</code> en formato <code>YYYY-MM-DD</code>).  Si no se especifican fechas, devuelve el conjunto m\u00e1s reciente de registros.  Incluye validaci\u00f3n interna que impide solicitar rangos en los que <code>hasta &lt; desde</code>.</p>"},{"location":"API_Flujo_Backfill/#imagen","title":"<code>/imagen</code>","text":"<p>Redirige a la \u00faltima imagen del cielo disponible en el servidor p\u00fablico.</p> <p>Si la imagen correspondiente al instante actual no est\u00e1 disponible, retrocede autom\u00e1ticamente 10 minutos.</p> <p>Se utiliza para visualizar la imagen en vivo en el dashboard.</p>"},{"location":"API_Flujo_Backfill/#satellite","title":"<code>/satellite</code>","text":"<p>Obtiene y devuelve una imagen satelital (PNG) con la capa de nubosidad proveniente de OpenWeatherMap.</p> <p>Se emplea como complemento visual para contrastar la predicci\u00f3n local con datos satelitales externos.</p>"},{"location":"API_Flujo_Backfill/#clima","title":"<code>/clima</code>","text":"<p>Consulta el estado meteorol\u00f3gico actual (temperatura, humedad, presi\u00f3n, viento, etc.) a trav\u00e9s del servicio OpenWeatherMap.</p> <p>Sirve para enriquecer el contexto de las predicciones generadas por el modelo y ofrecer una visi\u00f3n m\u00e1s completa en el dashboard.</p> <p>Conclusiones Finales: </p> <p>Estos endpoints permiten integrar los resultados del modelo con el entorno de visualizaci\u00f3n, ofreciendo acceso tanto a la predicci\u00f3n m\u00e1s reciente como a los registros hist\u00f3ricos y datos complementarios de clima y sat\u00e9lite.</p> <p>Todos los servicios manejan errores de red y validaciones internas para garantizar respuestas consistentes y actualizadas.</p> <p></p>"},{"location":"Guia_de_Uso/","title":"\ud83d\ude80 Gu\u00eda de Uso \u2014 Cielo R\u00edo Grande","text":"<p>Esta gu\u00eda explica c\u00f3mo obtener, instalar y ejecutar el proyecto Cielo R\u00edo Grande, levantar la API y acceder al dashboard de visualizaci\u00f3n.</p>"},{"location":"Guia_de_Uso/#1-clonar-el-repositorio","title":"\ud83e\udde9 1\ufe0f\u20e3 Clonar el Repositorio","text":"<p>Clon\u00e1 el repositorio desde GitHub y entr\u00e1 al directorio ra\u00edz del proyecto:</p> <pre><code>git clone https://github.com/&lt;usuario&gt;/Equipo-4-PP2-ASTRONOMICA-2C-2025.git\ncd Equipo-4-PP2-ASTRONOMICA-2C-2025\n</code></pre> <p>Si ya clonaste el repo antes, actualizalo con:</p> <pre><code>git pull\n</code></pre>"},{"location":"Guia_de_Uso/#2-backend-fastapi","title":"\u2699\ufe0f 2\ufe0f\u20e3 Backend (FastAPI)","text":"<p>\ud83d\udca1 El backend gestiona la l\u00f3gica de predicci\u00f3n, los endpoints y la base de datos local.</p>"},{"location":"Guia_de_Uso/#1-crear-y-activar-un-entorno-virtual-recomendado","title":"\ud83d\udd39 1. Crear y activar un entorno virtual (recomendado)","text":"<p>Primero, cre\u00e1 el entorno virtual con venv y activalo seg\u00fan tu sistema operativo \ud83d\udc47</p> <pre><code># Crear entorno virtual\npython -m venv venv\n\n# \ud83d\udc27 Linux / macOS\nsource venv/bin/activate\n\n# \ud83e\ude9f Windows\nvenv\\Scripts\\activate\n\n# \ud83d\udca1 Tip (PowerShell)\n# Si aparece un error de permisos al activar el entorno,\n# ejecut\u00e1 este comando para permitir scripts temporariamente:\nSet-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass\n ```\n\n### \ud83d\udd39 2. Instalar dependencias y ejecutar la API **sin hot reload**\n\n```bash\n# Ir al directorio del backend\ncd cielo-rio-grande/backend\n\n# Instalar dependencias del proyecto\npip install -r requirements.txt\n\n# \ud83e\uddea Opci\u00f3n 1 \u2014 Modo desarrollo (con hot reload)\n# Ideal mientras program\u00e1s: reinicia autom\u00e1ticamente el servidor al guardar cambios.\nuvicorn main:app --host 0.0.0.0 --port 8000 --reload\n\n# \ud83c\udfed Opci\u00f3n 2 \u2014 Modo producci\u00f3n (sin hot reload)\n# Recomendado para entornos estables o despliegues en servidores.\npython main.py\n\n# \ud83d\udca1 Tip:\n# Si quer\u00e9s habilitar el modo autom\u00e1tico de recarga (hot reload),\n# agreg\u00e1 la opci\u00f3n --reload al final del comando:\n# uvicorn main:app --host 0.0.0.0 --port 8000 --reload\n ```\n\n### 3. Abr\u00ed la documentaci\u00f3n interactiva (Swagger UI):  \n   \ud83d\udc49 [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)\n\n---\n\n## \ud83d\udcbb 3\ufe0f\u20e3 Frontend (React)\n\n\ud83d\udca1 El frontend muestra las predicciones, gr\u00e1ficos y reportes generados por el modelo.\n\n1. \ud83d\ude80 Levantar frontend del proyecto\n\n\nPaso previo: instalaci\u00f3n de Node.js y npm\n\nAntes de continuar, asegurate de tener instalados **Node.js** (versi\u00f3n 16 o superior) y **npm**.  \nPod\u00e9s verificarlo ejecutando:\n\n```bash\nnode -v\nnpm -v\n</code></pre> <p>Pasos</p> <pre><code># Entrar al directorio del frontend\ncd ../frontend          \n</code></pre> <pre><code># Instalar dependencias \n npm install   \n</code></pre> <pre><code># Iniciar el servidor de desarrollo\nnpm run start           \n</code></pre> <ol> <li> <p>Abrilo en tu navegador:    \ud83d\udc49 http://localhost:3000</p> </li> <li> <p>Desde ah\u00ed podr\u00e1s:  </p> <ul> <li>\ud83d\udcca Visualizar la evoluci\u00f3n de nubosidad  </li> <li>\ud83d\udcc5 Filtrar por rango de fechas  </li> <li>\ud83e\uddfe Exportar reportes en PDF</li> </ul> </li> </ol>"},{"location":"Guia_de_Uso/#4-backfill-procesamiento-historico","title":"\ud83d\udd01 4\ufe0f\u20e3 Backfill (Procesamiento Hist\u00f3rico)","text":"<p>\ud83d\udca1 El proceso de backfill reconstruye el historial de predicciones a partir de im\u00e1genes antiguas capturadas por la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande (EARG). Su prop\u00f3sito es generar un registro completo de nubosidad clasificada, abarcando d\u00edas o meses anteriores para an\u00e1lisis temporal y entrenamiento adicional del modelo.</p>"},{"location":"Guia_de_Uso/#descripcion-general","title":"\ud83e\udde0 Descripci\u00f3n general","text":"<p>El script <code>backfill.py</code> ejecuta un flujo automatizado que:</p> <ol> <li>\ud83d\uddd3\ufe0f Calcula el rango temporal solicitado (<code>--desde</code> y <code>--hasta</code> en formato ISO).  </li> <li>\u2601\ufe0f Consulta im\u00e1genes hist\u00f3ricas alojadas en el servidor EARG.  </li> <li>\ud83e\udde0 Aplica el modelo EfficientNet-B0 para predecir el nivel de nubosidad (0\u20138).  </li> <li>\ud83d\udcbe Guarda los resultados en <code>data/registros-octas.db</code>, evitando duplicados.  </li> <li>\ud83e\uddfe Registra logs detallados con progreso, errores y tiempos de ejecuci\u00f3n.</li> </ol>"},{"location":"Guia_de_Uso/#ejemplo-de-ejecucion","title":"\u2699\ufe0f Ejemplo de ejecuci\u00f3n","text":"<p>Procesar todas las im\u00e1genes del mes de enero de 2025:</p> <pre><code>cd cielo-rio-grande/backend\npython -m backfill --desde 2025-01-01T00:00 --hasta 2025-01-31T23:59\n</code></pre> <p>La salida mostrar\u00e1 un resumen como:</p> <pre><code>[2025-01-31 23:59] \u2705 Backfill completado:\ntotal = 864 | nuevos = 830 | duplicados = 28 | fallidos = 6\n</code></pre>"},{"location":"Guia_de_Uso/#caracteristicas-tecnicas","title":"\ud83e\udde9 Caracter\u00edsticas t\u00e9cnicas","text":"<ul> <li>\u26a1 Asincron\u00eda controlada: usa <code>asyncio</code> para manejar solicitudes HTTP en paralelo.  </li> <li>\ud83d\udd01 Reintentos autom\u00e1ticos: gestiona errores 408, 502, 503 y 504 con <code>Retry</code>.  </li> <li>\ud83e\uddf1 Logging estructurado: cada paso se registra en <code>logs/backfill.log</code>.  </li> <li>\ud83e\uddee Idempotencia: evita reprocesar im\u00e1genes ya almacenadas.  </li> <li>\ud83e\uddf5 Concurrencia: l\u00edmite recomendado de 3\u20136 workers en entornos locales.</li> </ul>"},{"location":"Guia_de_Uso/#resultado-final","title":"\ud83d\udce6 Resultado final","text":"<ul> <li>Base de datos actualizada: <code>data/registros-octas.db</code> </li> <li>Registros ordenados por timestamp (<code>fecha_prediccion</code>)  </li> <li>Logs detallados: <code>logs/backfill.log</code> </li> <li>Visualizaci\u00f3n disponible desde el dashboard React</li> </ul> <p>El backfill es clave para mantener una base de datos completa y coherente con las predicciones en tiempo real.</p>"},{"location":"Guia_de_Uso/#5-visualizacion-de-resultados","title":"\ud83d\udcca 5\ufe0f\u20e3 Visualizaci\u00f3n de Resultados","text":"<p>El dashboard React permite:</p> <ul> <li>\ud83d\udcc8 Consultar el historial de predicciones  </li> <li>\ud83d\udcc6 Visualizar gr\u00e1ficos de nubosidad por fecha  </li> <li>\ud83d\udce4 Exportar reportes en PDF  </li> <li>\ud83e\uddee Analizar tendencias mediante indicadores din\u00e1micos</li> </ul>"},{"location":"Guia_de_Uso/#6-endpoints-principales","title":"\ud83e\udde0 6\ufe0f\u20e3 Endpoints Principales","text":"Endpoint M\u00e9todo Descripci\u00f3n <code>/octas</code> GET Retorna la \u00faltima predicci\u00f3n generada <code>/historial</code> GET Devuelve registros hist\u00f3ricos filtrables por fecha <code>/imagen</code> GET Obtiene la \u00faltima imagen procesada <code>/satellite</code> GET Muestra imagen satelital de nubosidad <code>/clima</code> GET Proporciona datos meteorol\u00f3gicos actuales"},{"location":"Guia_de_Uso/#7-verificacion-final","title":"\u2705 7\ufe0f\u20e3 Verificaci\u00f3n Final","text":"<ul> <li>\ud83d\udfe2 La API muestra <code>Application startup complete</code> en consola.  </li> <li>\ud83d\udfe2 El dashboard carga correctamente en http://localhost:3000.  </li> <li>\ud83d\udfe2 La base <code>registros-octas.db</code> se actualiza tras ejecutar el backfill.  </li> </ul> <p>Si todo esto sucede, tu entorno est\u00e1 listo \ud83d\ude80</p>"},{"location":"Guia_de_Uso/#creditos","title":"\u2728 Cr\u00e9ditos","text":"<p>Desarrollado por el Equipo 4 \u2013 PP2 Astron\u00f3mica (2C 2025) para la Tecnicatura Superior en Ciencia de Datos e Inteligencia Artificial del Polit\u00e9cnico Malvinas Argentinas, en colaboraci\u00f3n con la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande (EARG).</p> <p></p>"},{"location":"Manual_de_usuario/","title":"Manual de Usuario","text":"<p>Manual de Usuario</p> <p>Cielo R\u00edo Grande es un sistema desarrollado con el prop\u00f3sito de facilitar la visualizaci\u00f3n en tiempo real del cielo de la ciudad de R\u00edo Grande y la clasificaci\u00f3n autom\u00e1tica del nivel de nubosidad mediante un modelo de inteligencia artificial entrenado con im\u00e1genes astron\u00f3micas locales.</p> <p>El proyecto est\u00e1 dirigido a la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande (EARG) y a la comunidad cient\u00edfica y educativa del Centro Polit\u00e9cnico Malvinas Argentinas, as\u00ed como a toda persona interesada en el monitoreo atmosf\u00e9rico y la observaci\u00f3n astron\u00f3mica automatizada.</p> <p>El sistema permite observar el estado actual del cielo y obtener una predicci\u00f3n autom\u00e1tica del nivel de nubosidad expresado en octas (de 0 a 8), facilitando el registro y an\u00e1lisis de condiciones atmosf\u00e9ricas locales en apoyo a tareas de observaci\u00f3n astron\u00f3mica, investigaci\u00f3n educativa y proyectos de ciencia ciudadana.</p> <p>Alcance Hace:</p> <ul> <li> <p>Clasifica im\u00e1genes del cielo seg\u00fan su nivel de nubosidad (0\u20138 octas).</p> </li> <li> <p>Muestra el estado del cielo en vivo a trav\u00e9s de una interfaz web.</p> </li> <li> <p>Gestiona datos meteorol\u00f3gicos e hist\u00f3ricos.</p> </li> <li> <p>Expone informaci\u00f3n mediante una API para integraci\u00f3n con otros sistemas.</p> </li> </ul> <p>No hace:</p> <ul> <li> <p>No controla ni opera equipos astron\u00f3micos.</p> </li> <li> <p>No realiza predicciones meteorol\u00f3gicas completas.</p> </li> <li> <p>No reemplaza las observaciones profesionales de los t\u00e9cnicos del observatorio.</p> </li> </ul> <p>Plataforma y tecnolog\u00eda</p> <p>Cielo R\u00edo Grande funciona como una aplicaci\u00f3n web compuesta por un backend desarrollado en FastAPI (Python) y un frontend en React, lo que permite su uso tanto en entornos locales como remotos.</p> <p>Roles de usuario</p> <ul> <li> <p>Investigadores y t\u00e9cnicos de la EARG: uso operativo y validaci\u00f3n de resultados.</p> </li> <li> <p>Estudiantes y docentes: utilizaci\u00f3n con fines acad\u00e9micos y de experimentaci\u00f3n.</p> </li> <li> <p>Usuarios p\u00fablicos: acceso a la visualizaci\u00f3n del cielo y estad\u00edsticas b\u00e1sicas.</p> </li> </ul> <p>Entorno de ejecuci\u00f3n</p> <p>El sistema puede ejecutarse en entornos locales o en el servidor de la EARG, con posibilidad de despliegue en plataformas en la nube (como Google Colab o entornos con GPU compatibles).</p> <p>Requisitos m\u00ednimos</p> <ul> <li> <p>Sistema operativo: Windows 10+, Linux o macOS.</p> </li> <li> <p>Memoria RAM: m\u00ednimo 8 GB (recomendado 16 GB).</p> </li> <li> <p>Software necesario: Python 3.10+, Node.js 18+, navegador Chrome o Edge actualizado.</p> </li> <li> <p>GPU (opcional): compatible con CUDA para entrenamiento.</p> </li> </ul> <p>Acceso al sistema</p> <ul> <li> <p>Backend: http://127.0.0.1:8000</p> </li> <li> <p>Frontend: http://localhost:3000</p> </li> </ul> <p>Instalaci\u00f3n y configuraci\u00f3n</p> <p>El proyecto se encuentra en un \u00fanico repositorio GitHub:</p> <p>https://github.com/casescas/Equipo-4-PP2-ASTRONOMICA-2C-2025</p> <p>Dentro del repositorio, la aplicaci\u00f3n completa est\u00e1 organizada en la carpeta principal: cielo-rio-grande/</p> <ul> <li>/backend: implementaci\u00f3n de la API en FastAPI (Python).  </li> <li>/frontend: interfaz de usuario desarrollada en React.</li> </ul> <p>1. Clonar repositorio </p> <p></p> <p>Luego, para ingresar a la carpeta del proyecto principal, ejecutar:</p> <p></p> <p>2. Instalar dependencias</p> <p>Backend:</p> <ol> <li>Ingresar a la carpeta del backend:</li> </ol> <p></p> <ol> <li>(Opcional pero recomendado) crear entorno virtual:</li> </ol> <p></p> <p></p> <ol> <li>Instalar dependencias del backend:</li> </ol> <p></p> <p>Frontend: </p> <ol> <li>Ingresar a la carpeta del frontend: </li> <li>Instalar dependencias del frontend:</li> </ol> <p></p> <p>3.Inicio del sistema:</p> <ol> <li>Backend: </li> </ol> <p>Ejecutar la carpeta</p> <p></p> <p>Nos indica que el backend FastApi est\u00e1 funcionando correctamente. Corre en el puerto 8000 \u2192 http://127.0.0.1:8000</p> <ol> <li>Frontend:</li> </ol> <p></p> <p> Nos indica que el frontend React est\u00e1 iniciado y funcionando correctamente.</p> <p>Una vez activos ambos servicios, se abre autom\u00e1ticamente la web en el navegador predeterminado o ingresando a: http://localhost:3000 No se requiere inicio de sesi\u00f3n; el acceso es directo y libre para los usuarios del entorno local o de red interna.</p> <p>Uso del sistema</p> <p>La interfaz principal de Cielo R\u00edo Grande se presenta en una \u00fanica pantalla que combina la imagen del cielo capturada por la c\u00e1mara astron\u00f3mica en tiempo real junto con los resultados del modelo de clasificaci\u00f3n. Adem\u00e1s, incorpora informaci\u00f3n meteorol\u00f3gica detallada (como temperatura, humedad, viento, presi\u00f3n y descripci\u00f3n del clima), datos de radiaci\u00f3n solar e \u00edndice UV, vistas satelitales y de radar, y un panel de anal\u00edticas de nubosidad con estad\u00edsticas globales, gr\u00e1ficos y opciones de exportaci\u00f3n de datos.</p> <p>Secci\u00f3n superior: vista general del cielo y clasificaci\u00f3n de nubes</p> <p></p> <p>En la parte izquierda se muestra una imagen est\u00e1tica actualizada autom\u00e1ticamente cada 10 minutos, la imagen procede del sitio oficial del observatorio: http://201.251.63.225/meteorologia/cielo/image/</p> <p>A la derecha, el panel \u201cModelo de Clasificaci\u00f3n de Nubes\u201d expone la informaci\u00f3n generada por la inteligencia artificial, a partir de la imagen actual del cielo. Este panel es solo informativo y no requiere interacci\u00f3n del usuario. Los datos principales que presenta son:</p> <ul> <li> <p>Cobertura (%): indica el porcentaje estimado del cielo cubierto por nubes.</p> </li> <li> <p>Tipo dominante: muestra la abreviatura y descripci\u00f3n general del tipo de nubosidad (por ejemplo, \u201cSCT \u2014 Nubes dispersas\u201d).</p> </li> <li> <p>Octas: representa el nivel de nubosidad total en una escala de 0 a 8 (seg\u00fan la clasificaci\u00f3n internacional de octas).</p> </li> <li> <p>Confianza (%): nivel de certeza del modelo respecto a la clasificaci\u00f3n mostrada, acompa\u00f1ado de un gr\u00e1fico circular de color verde que facilita su lectura visual.</p> </li> </ul> <p>En la parte inferior del panel se especifica el modelo de IA utilizado (por ejemplo: EfficientNet-B0) y el modo de inferencia actual (local o remoto).</p> <p>Secci\u00f3n media: informaci\u00f3n meteorol\u00f3gica y radiaci\u00f3n solar</p> <p></p> <p>La secci\u00f3n media de la interfaz concentra la informaci\u00f3n meteorol\u00f3gica general y los indicadores de radiaci\u00f3n solar, UV y cobertura satelital. Se compone de tres m\u00f3dulos principales:</p> <ul> <li> <p>Clima Detallado: muestra los datos actuales de temperatura, sensaci\u00f3n t\u00e9rmica, humedad, direcci\u00f3n y velocidad del viento, presi\u00f3n atmosf\u00e9rica y una breve descripci\u00f3n del estado del cielo.   Estos valores se obtienen autom\u00e1ticamente de la API de OpenWeatherMap, un servicio meteorol\u00f3gico global que actualiza los datos en tiempo real.</p> </li> <li> <p>Radiaci\u00f3n Solar y UV: presenta los valores de radiaci\u00f3n actual (en W/m\u00b2), el \u00edndice UV y su nivel de riesgo asociado (bajo, moderado o alto).   Los datos provienen mediante web scraping de la p\u00e1gina meteorol\u00f3gica local de la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande   (http://201.251.63.225/meteorologia/vp2s1/vantalhb.htm)   y se actualizan en tiempo real, reflejando las condiciones medidas por los sensores de la estaci\u00f3n.</p> </li> <li> <p>Sat\u00e9lite / Radar: permite visualizar una vista satelital o radar de la nubosidad. Al presionar el bot\u00f3n \u201cVer Nubes\u201d, se activa la visualizaci\u00f3n, cargando la imagen satelital o radar correspondiente. El bot\u00f3n \u201cLimpiar\u201d desactiva o limpia la vista, volviendo al estado inicial del panel.</p> </li> </ul> <p>Secci\u00f3n inferior: anal\u00edticas de nubosidad \u2013 evoluci\u00f3n y comportamiento</p> <p>La secci\u00f3n inferior de la interfaz presenta el panel de Anal\u00edticas de Nubosidad, donde se visualizan m\u00e9tricas globales y estad\u00edsticas hist\u00f3ricas generadas autom\u00e1ticamente por el sistema. Estas anal\u00edticas permiten evaluar el rendimiento del modelo y observar la evoluci\u00f3n del cielo a lo largo del tiempo.</p> <p>El panel de anal\u00edticas se actualiza de forma continua leyendo directamente de esa base de datos, lo que permite que las gr\u00e1ficas y tablas se mantengan sincronizadas sin intervenci\u00f3n del usuario.</p> <p>Los indicadores principales que se muestran en la parte superior del panel son:</p> <ul> <li> <p>Total de im\u00e1genes procesadas: cantidad total de observaciones analizadas por el modelo.</p> </li> <li> <p>Tiempo de predicci\u00f3n promedio: duraci\u00f3n media del proceso de inferencia (en segundos).</p> </li> <li> <p>Octas global promedio: valor medio de nubosidad acumulado en el per\u00edodo seleccionado.</p> </li> <li> <p>Confianza promedio: porcentaje promedio de certeza del modelo en las predicciones.</p> </li> </ul> <p>A continuaci\u00f3n se presenta un gr\u00e1fico de l\u00edneas que muestra la variaci\u00f3n de nubosidad (octas por hora) seg\u00fan el rango temporal elegido \u2014d\u00eda, semana, mes o rango personalizado\u2014, y un gr\u00e1fico circular de distribuci\u00f3n que indica la frecuencia de cada categor\u00eda de nubosidad.</p> <p>Debajo de los gr\u00e1ficos, la tabla de resumen detalla los valores promedio y las categor\u00edas dominantes del per\u00edodo analizado.</p> <p></p> <p>Los botones de exportaci\u00f3n permiten conservar o compartir los resultados:</p> <ul> <li> <p>PDF: genera un informe visual de toda la secci\u00f3n de anal\u00edticas, incluyendo gr\u00e1ficos y tabla de resumen.</p> </li> <li> <p>CSV / Excel: exportan los datos num\u00e9ricos de la tabla inferior (promedios, categor\u00edas dominantes, porcentajes, etc.), de acuerdo con el filtro temporal aplicado.</p> </li> </ul> <p>Flujo de trabajo t\u00edpico</p> <ol> <li> <p>Acceso al sistema:    El usuario ingresa al sitio web principal de la aplicaci\u00f3n desde un navegador compatible, accediendo a la direcci\u00f3n http://localhost:3000 o a la URL asignada por la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande.</p> </li> <li> <p>Carga autom\u00e1tica de informaci\u00f3n:    Al iniciar la aplicaci\u00f3n, el sistema actualiza autom\u00e1ticamente la imagen del cielo (cada 10 minutos) y los datos meteorol\u00f3gicos asociados \u2014temperatura, humedad, presi\u00f3n, viento, radiaci\u00f3n solar e \u00edndice UV\u2014 sin necesidad de presionar ning\u00fan bot\u00f3n.</p> </li> <li> <p>Visualizaci\u00f3n del modelo de IA:    En la parte superior de la interfaz, el panel de Modelo de Clasificaci\u00f3n de Nubes muestra el resultado de la \u00faltima inferencia: porcentaje de cobertura, tipo dominante de nubosidad, cantidad de octas y nivel de confianza de la predicci\u00f3n.</p> </li> <li> <p>Consulta del radar satelital:    En caso de desear visualizar la cobertura de nubes por radar o sat\u00e9lite, el usuario puede presionar el bot\u00f3n \u201cVer Nubes\u201d en la secci\u00f3n correspondiente.    Este es el \u00fanico elemento interactivo de la p\u00e1gina principal; al activarlo se cargan las im\u00e1genes de radar. El bot\u00f3n \u201cLimpiar\u201d permite regresar al estado inicial.</p> </li> <li> <p>Exploraci\u00f3n de anal\u00edticas y estad\u00edsticas:    En la parte inferior del sitio, el panel de Anal\u00edticas de Nubosidad presenta la evoluci\u00f3n del cielo durante el d\u00eda, con gr\u00e1ficos, promedios y categor\u00edas predominantes.    Estas m\u00e9tricas se actualizan autom\u00e1ticamente en funci\u00f3n de las observaciones almacenadas por el sistema.</p> </li> <li> <p>Exportaci\u00f3n de informaci\u00f3n (opcional):    Si el usuario desea conservar o compartir los resultados, puede utilizar los botones de exportaci\u00f3n:</p> </li> <li> <p>PDF: genera un informe visual con los gr\u00e1ficos y la tabla de resumen.</p> </li> <li> <p>CSV / Excel: descargan los datos num\u00e9ricos agregados del per\u00edodo seleccionado.</p> </li> </ol> <p>De este modo, el flujo de uso del sistema es mayormente pasivo y orientado a la observaci\u00f3n, brindando informaci\u00f3n meteorol\u00f3gica y anal\u00edtica actualizada de forma continua y accesible desde un \u00fanico entorno web.</p> <p>Actualizaci\u00f3n del modelo de inteligencia artificial</p> <p>El sistema Cielo R\u00edo Grande est\u00e1 dise\u00f1ado para operar de manera continua y aut\u00f3noma. Cuando se dispone de una nueva versi\u00f3n del modelo de clasificaci\u00f3n, la actualizaci\u00f3n se realiza de forma manual siguiendo estos pasos:</p> <ol> <li> <p>Reemplazar el archivo del modelo en el directorio: cielo-rio-grande/backend/models/    Puede hacerse de dos maneras:</p> </li> <li> <p>Sustituyendo el archivo existente mejor_modelo_efficientnet_finetuning.pth por la nueva versi\u00f3n, manteniendo el mismo nombre.</p> </li> <li> <p>O bien, agregando un nuevo archivo con otro nombre y actualizando la variable OCTAS_MODEL_PATH en el archivo backend/config/config.py para que apunte al nuevo modelo.</p> </li> <li> <p>Reiniciar el servidor del backend.    Una vez reiniciado, el sistema cargar\u00e1 el nuevo modelo autom\u00e1ticamente y comenzar\u00e1 a utilizarlo en las predicciones siguientes.</p> </li> </ol> <p>Cada predicci\u00f3n que realiza el sistema registra, adem\u00e1s de los resultados de nubosidad, la versi\u00f3n del modelo utilizada, almacen\u00e1ndola en la base de datos en la columna modelo_version. Esto permite mantener la trazabilidad de los resultados y conocer qu\u00e9 versi\u00f3n del modelo gener\u00f3 cada registro hist\u00f3rico.</p> <p>Problemas frecuentes y mantenimiento preventivo</p> <p>En virtud de la integraci\u00f3n entre componentes locales y servicios meteorol\u00f3gicos externos, se establecieron lineamientos de mantenimiento preventivo destinados a preservar la confiabilidad, estabilidad y continuidad operativa del sistema Cielo R\u00edo Grande.</p> <p>Integraci\u00f3n con servicios externos</p> <p>El sistema se conecta de manera permanente con fuentes meteorol\u00f3gicas y de observaci\u00f3n, tales como la c\u00e1mara astron\u00f3mica local, la API de OpenWeatherMap y la p\u00e1gina meteorol\u00f3gica de la EARG. </p> <p>Para asegurar su correcto funcionamiento:</p> <ul> <li> <p>Se recomienda verificar peri\u00f3dicamente la disponibilidad de los servicios externos y mantener actualizadas las credenciales de acceso (por ejemplo, la API Key de OpenWeatherMap).</p> </li> <li> <p>Ante modificaciones en las fuentes de datos (estructura web o formato), el sistema permite ajustar r\u00e1pidamente los scripts de extracci\u00f3n o reemplazarlos por interfaces API equivalentes, sin afectar el resto de la arquitectura.</p> </li> </ul> <p>Actualizaci\u00f3n del modelo de inteligencia artificial El proceso de actualizaci\u00f3n del modelo ha sido dise\u00f1ado para ser simple y trazable. Reemplazando el archivo de pesos del modelo en el directorio correspondiente o actualizando la variable de configuraci\u00f3n OCTAS_MODEL_PATH, el sistema carga autom\u00e1ticamente la nueva versi\u00f3n tras reiniciar el backend. Para prevenir inconsistencias, se recomienda:</p> <ul> <li> <p>Verificar previamente la compatibilidad del nuevo modelo con la estructura del servicio.</p> </li> <li> <p>Mantener una copia de respaldo del modelo anterior antes de la actualizaci\u00f3n.</p> </li> <li> <p>Documentar la versi\u00f3n utilizada en cada despliegue (el sistema ya registra esta informaci\u00f3n en la base de datos de manera autom\u00e1tica).</p> </li> </ul> <p>Base de datos y almacenamiento La base de datos de predicciones (registros-octas.db) almacena todo el historial operativo. Para garantizar su integridad:</p> <ul> <li> <p>Se sugiere realizar copias de seguridad peri\u00f3dicas y monitorear el espacio disponible en disco.</p> </li> <li> <p>En entornos de alta carga, puede configurarse la rotaci\u00f3n o archivado autom\u00e1tico de registros antiguos.</p> </li> </ul> <p>Entorno y dependencias El correcto funcionamiento del sistema depende de la coherencia entre las versiones de software utilizadas.</p> <ul> <li> <p>Se recomienda mantener los entornos controlados y documentar las versiones exactas de Python, Node.js y librer\u00edas asociadas (seg\u00fan requirements.txt y package.json).</p> </li> <li> <p>En actualizaciones mayores, probar previamente la instalaci\u00f3n en un entorno de prueba para evitar conflictos o comportamientos inesperados.</p> </li> </ul> <p>Estructura general del sistema </p> <p></p> <p>Anexo T\u00e9cnico</p> <p>Glosario de t\u00e9rminos clave</p> <p>Octas: unidad utilizada en meteorolog\u00eda para medir la cobertura nubosa. Va de 0 (cielo despejado) a 8 (totalmente cubierto).</p> <p>Inferencia:** proceso por el cual un modelo de IA entrenado recibe nuevos datos (una imagen) y genera una predicci\u00f3n (porcentaje de nubosidad, tipo de nube, etc.).</p> <p>Confianza del modelo:** porcentaje que refleja cu\u00e1n seguro est\u00e1 el modelo de IA sobre la predicci\u00f3n realizada.</p> <p>Openweathermap: servicio meteorol\u00f3gico global que ofrece datos clim\u00e1ticos en tiempo real a trav\u00e9s de una API.</p> <p>Scraper / web scraping:** t\u00e9cnica que permite obtener informaci\u00f3n desde p\u00e1ginas web. En este sistema se usa para leer datos de radiaci\u00f3n local.</p> <p>Backend: parte del sistema que procesa la l\u00f3gica interna, se comunica con los servicios externos y ejecuta el modelo de IA.</p> <p>Frontend: interfaz visual que permite al usuario interactuar con los datos y visualizar los resultados.</p> <p>Cr\u00e9ditos y referencias</p> <p>Equipo 4 de Astron\u00f3mica</p> <p>Carmueda, Juan Pablo Estrada, Diego Gonz\u00e1lez Sardi, Iara Quinteros, Francisco Nicol\u00e1s Isa, Facundo Nicol\u00e1s</p> <p>Instituci\u00f3n: Centro Politecnico Superior Malvinas Argentinas.</p> <p>Proyecto: Sistema de Monitoreo y Predicci\u00f3n de Cobertura Nubosa (Cielo Rio Grande)</p> <p>Tecnolog\u00edas y librer\u00edas principales: -Backend: Python \u00b7 FastAPI (API REST) \u00b7 PyTorch &amp; TensorFlow (modelo IA) \u00b7 OpenCV (procesamiento de im\u00e1genes) \u00b7 APScheduler (tareas programadas) \u00b7 BeautifulSoup4 (web scraping)</p> <p>-Frontend: React.js \u00b7 Tailwind CSS \u00b7 Recharts (gr\u00e1ficos) \u00b7 jsPDF y xlsx (exportaci\u00f3n de datos)</p> <p>-Modelo IA: EfficientNetB0 (arquitectura base de clasificaci\u00f3n de im\u00e1genes)</p> <p>Fuentes de datos:</p> <ul> <li> <p>Imagen del cielo obtenida desde la p\u00e1gina oficial de la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande (EARG): http://201.251.63.225/meteorologia/cielo/image/</p> </li> <li> <p>API de OpenWeatherMap (datos meteorol\u00f3gicos):  https://openweathermap.org/api</p> </li> <li> <p>Web local EARG para radiaci\u00f3n solar: http://201.251.63.225/meteorologia/vp2s1/vantalhb.htm</p> </li> </ul> <p>Repositorio oficial: https://github.com/casescas/Equipo-4-PP2-ASTRONOMICA-2C-2025</p> <p>Referencias t\u00e9cnicas:</p> <ul> <li> <p>Documentaci\u00f3n oficial de FastAPI</p> </li> <li> <p>Gu\u00eda de modelos EfficientNet \u2013 TensorFlow Hub y PyTorch Hub</p> </li> <li> <p>Documentaci\u00f3n de OpenWeatherMap API</p> </li> <li> <p>Tailwind CSS Docs (https://tailwindcss.com/docs)</p> </li> <li> <p>APScheduler Docs (https://apscheduler.readthedocs.io/en/stable/)</p> </li> </ul> <p></p>"},{"location":"Plan_de_Escalamiento/","title":"\ud83d\ude80 Escalamiento del Proyecto Cielo R\u00edo Grande","text":""},{"location":"Plan_de_Escalamiento/#objetivo-del-escalamiento","title":"\ud83c\udfaf Objetivo del Escalamiento","text":"<p>El objetivo principal del escalamiento del sistema de monitoreo atmosf\u00e9rico automatizado desarrollado en el marco del proyecto Cielo R\u00edo Grande es ampliar sus capacidades t\u00e9cnicas, operativas y territoriales, consolidando una plataforma robusta, modular y replicable para la clasificaci\u00f3n de nubosidad, detecci\u00f3n de nubes noctilucentes (NLCs) y an\u00e1lisis meteorol\u00f3gico en tiempo real.</p> <p>Este escalamiento busca:</p> <ul> <li>Mejorar la precisi\u00f3n del modelo de clasificaci\u00f3n de nubosidad, especialmente en los niveles intermedios de octas (4, 5 y 6), mediante el enriquecimiento del dataset, la incorporaci\u00f3n de arquitecturas alternativas y el ajuste de t\u00e9cnicas de entrenamiento que permitan una mejor generalizaci\u00f3n.</li> <li>Integrar nuevas funcionalidades de an\u00e1lisis atmosf\u00e9rico, como la detecci\u00f3n autom\u00e1tica de NLCs y la correlaci\u00f3n con variables meteorol\u00f3gicas (vapor de agua GNSS, radiaci\u00f3n solar, temperatura superficial).</li> <li>Expandir el sistema a otras estaciones astron\u00f3micas o meteorol\u00f3gicas, replicando la arquitectura modular de captura, procesamiento y visualizaci\u00f3n, y promoviendo la interoperabilidad entre observatorios.</li> <li>Fortalecer la trazabilidad y confiabilidad de los datos, mejorando el pipeline autom\u00e1tico, el backfill hist\u00f3rico y la validaci\u00f3n cruzada de registros.</li> <li>Abrir el sistema a la comunidad cient\u00edfica y educativa, publicando una API REST documentada y dashboards interactivos, promoviendo el desarrollo de proyectos innovadores basados en los datos recolectados.</li> </ul> <p>\ud83d\udef0\ufe0f En s\u00edntesis, el escalamiento del proyecto apunta a consolidar una soluci\u00f3n integral, escalable y replicable para el monitoreo inteligente del cielo, combinando visi\u00f3n artificial, ciencia de datos y meteorolog\u00eda aplicada.</p>"},{"location":"Plan_de_Escalamiento/#estrategias-de-escalamiento","title":"\u2699\ufe0f Estrategias de Escalamiento","text":"<p>A continuaci\u00f3n se detallan las acciones propuestas en cada eje estrat\u00e9gico:</p>"},{"location":"Plan_de_Escalamiento/#a-tecnicas-de-mejora-de-modelos","title":"A. T\u00e9cnicas de Mejora de Modelos","text":"<ul> <li>Clasificaci\u00f3n ordinal: reemplazar la clasificaci\u00f3n categ\u00f3rica por un enfoque ordinal que reconozca la progresi\u00f3n continua entre niveles de octas, reduciendo la confusi\u00f3n entre clases vecinas.  </li> <li>Exploraci\u00f3n de arquitecturas alternativas: evaluar modelos m\u00e1s avanzados como ConvNeXt o Swin Transformers, capaces de capturar mejor las caracter\u00edsticas visuales en im\u00e1genes astron\u00f3micas.</li> </ul>"},{"location":"Plan_de_Escalamiento/#b-expansion-del-dataset","title":"B. Expansi\u00f3n del Dataset","text":"<ul> <li>Recolecci\u00f3n activa de im\u00e1genes intermedias: campa\u00f1as de captura focalizadas en niveles de nubosidad poco representados (octas 4, 5 y 6), tanto en condiciones claras como oscuras.  </li> <li>Generaci\u00f3n sint\u00e9tica con GANs: uso de redes generativas adversarias para crear im\u00e1genes artificiales que refuercen clases minoritarias, manteniendo coherencia visual con el dominio astron\u00f3mico.  </li> <li>Etiquetado colaborativo y revisi\u00f3n cruzada: sistema distribuido de validaci\u00f3n manual entre m\u00faltiples observadores, con revisi\u00f3n cruzada y enlaces a im\u00e1genes de otras estaciones astron\u00f3micas o meteorol\u00f3gicas, promoviendo la estandarizaci\u00f3n del etiquetado y la mejora continua del modelo.</li> </ul>"},{"location":"Plan_de_Escalamiento/#c-integracion-de-nuevas-funcionalidades","title":"C. Integraci\u00f3n de Nuevas Funcionalidades","text":"<ul> <li>M\u00f3dulo de detecci\u00f3n de NLCs: entrenamiento de una red neuronal espec\u00edfica para identificar nubes noctilucentes, centrada en im\u00e1genes con \u00e1ngulo solar entre -7\u00b0 y -10.5\u00b0 durante diciembre y enero.  </li> <li>Correlaci\u00f3n con datos GNSS y radiaci\u00f3n solar: incorporaci\u00f3n de variables meteorol\u00f3gicas como vapor de agua GNSS, radiaci\u00f3n solar y temperatura superficial, para generar modelos h\u00edbridos que combinen visi\u00f3n artificial con datos num\u00e9ricos.  </li> <li>Dashboard avanzado con alertas y capas satelitales: integraci\u00f3n de datos satelitales (OpenWeatherMap, GOES) y alertas autom\u00e1ticas ante cambios de nubosidad o detecci\u00f3n de NLCs.  </li> <li>An\u00e1lisis temporal y predicci\u00f3n futura: uso de modelos de series temporales (LSTM, Prophet) para predecir la evoluci\u00f3n de la nubosidad y anticipar ventanas de cielo despejado.  </li> <li>Comparaci\u00f3n con im\u00e1genes de otras estaciones: galer\u00eda de referencia y consulta cruzada con c\u00e1maras de Ezeiza, Bariloche, Ushuaia u otras estaciones.</li> </ul>"},{"location":"Plan_de_Escalamiento/#d-escalamiento-territorial-e-institucional","title":"D. Escalamiento Territorial e Institucional","text":"<ul> <li>Replicaci\u00f3n del sistema: adaptaci\u00f3n de la arquitectura modular para su implementaci\u00f3n en nuevos observatorios astron\u00f3micos o meteorol\u00f3gicos, manteniendo compatibilidad con el pipeline actual.  </li> <li>Convenios institucionales: acuerdos con universidades, institutos t\u00e9cnicos y organismos meteorol\u00f3gicos para compartir datos, validar modelos y ampliar cobertura territorial.  </li> <li>Publicaci\u00f3n abierta de la API REST: acceso libre y documentado a predicciones, im\u00e1genes procesadas y datos meteorol\u00f3gicos, fomentando la colaboraci\u00f3n educativa, cient\u00edfica y tecnol\u00f3gica.</li> </ul>"},{"location":"Plan_de_Escalamiento/#conclusion","title":"\ud83e\udded Conclusi\u00f3n","text":"<p>El escalamiento del proyecto Cielo R\u00edo Grande representa una oportunidad estrat\u00e9gica para consolidar un sistema inteligente de monitoreo atmosf\u00e9rico que combina visi\u00f3n artificial, ciencia de datos y meteorolog\u00eda aplicada.</p> <p>A trav\u00e9s de la mejora de modelos, la expansi\u00f3n del dataset, la integraci\u00f3n de nuevas funcionalidades y la apertura institucional, se busca fortalecer la precisi\u00f3n, la interoperabilidad y el impacto del sistema tanto a nivel local como regional.</p> <p>La incorporaci\u00f3n de tecnolog\u00edas avanzadas \u2014como arquitecturas modernas, clasificaci\u00f3n ordinal, an\u00e1lisis temporal y correlaci\u00f3n con datos GNSS\u2014 permitir\u00e1 abordar los desaf\u00edos actuales en la clasificaci\u00f3n de nubosidad y enriquecer el an\u00e1lisis atmosf\u00e9rico.</p> <p>\ud83c\udf20 Este plan estrat\u00e9gico apunta a transformar Cielo R\u00edo Grande en una plataforma de referencia para la observaci\u00f3n automatizada del cielo, con potencial de replicaci\u00f3n en otras estaciones y aplicaciones en \u00e1mbitos cient\u00edficos, t\u00e9cnicos y educativos.</p> <p></p>"},{"location":"Reporte_EfficientNet_B0/","title":"Reporte de modelo EfficientNet_B0","text":"<p>Documentaci\u00f3n del Modelo EfficientNet-B0</p> <p>El presente documento tiene como prop\u00f3sito describir el desarrollo y funcionamiento del modelo de clasificaci\u00f3n EfficientNet-B0, implementado en el marco del proyecto de colaboraci\u00f3n con la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande (EARG). Este modelo constituye uno de los componentes del sistema de inteligencia artificial orientado a la detecci\u00f3n autom\u00e1tica del nivel de nubosidad (octas) en im\u00e1genes del cielo.</p> <p>El modelo EfficientNet-B0 fue entrenado para identificar, en fotograf\u00edas del cielo capturadas por la EARG, la cantidad relativa de nubes presentes, expresada en la escala meteorol\u00f3gica de 0 a 8 octas, donde 0 representa un cielo completamente despejado y 8 uno totalmente cubierto. Su finalidad principal es automatizar la clasificaci\u00f3n del estado del cielo a partir de im\u00e1genes obtenidas por la EARG, permitiendo reducir el tiempo de an\u00e1lisis manual, estandarizar criterios de observaci\u00f3n y generar bases de datos etiquetadas que faciliten estudios posteriores sobre condiciones atmosf\u00e9ricas locales.</p> <p>La elecci\u00f3n de EfficientNet-B0 se realiz\u00f3 tras comparar su desempe\u00f1o con otros modelos como EfficientNet-B3, B4, B5, VisionMixTransformers y TensorFlow-Kerak.  EfficientNet-B0 responde a su eficiencia computacional y capacidad de generalizaci\u00f3n, caracter\u00edsticas que la convierten en una arquitectura adecuada para entornos con recursos limitados de c\u00f3mputo. En este contexto, el modelo constituye una primera instancia dentro de un sistema escalable que busca mejorar la gesti\u00f3n y planificaci\u00f3n de las observaciones astron\u00f3micas, incorporando progresivamente nuevas fuentes de datos y modelos complementarios, como la detecci\u00f3n de nubes noctilucentes y la correlaci\u00f3n con variables meteorol\u00f3gicas (radiaci\u00f3n solar y vapor de agua), lo que permitir\u00e1 fortalecer el monitoreo atmosf\u00e9rico automatizado de la estaci\u00f3n.</p> <p>Preparaci\u00f3n del Dataset</p> <p>El conjunto de datos utilizado para el entrenamiento y validaci\u00f3n del modelo EfficientNet-B0 corresponde a la carpeta \u201c05.Etiquetado_Final\u201d, ubicada tanto en el repositorio del proyecto en GitHub como en el espacio compartido de Google Drive.</p> <p>El dataset se organiza en dieciocho carpetas principales, diferenciadas por tipo de iluminaci\u00f3n (clara u oscura) y nivel de nubosidad seg\u00fan la escala de 0 a 8 octas:</p> <ul> <li> <p>im\u00e1genes_clara_octa_0 a im\u00e1genes_clara_octa_8</p> </li> <li> <p>im\u00e1genes_oscura_octa_0 a im\u00e1genes_oscura_octa_8</p> </li> </ul> <p>Esta estructura permite mantener una jerarqu\u00eda clara para su uso en los procesos de carga y entrenamiento del modelo.</p> <p>El an\u00e1lisis exploratorio evidenci\u00f3 una distribuci\u00f3n desigual entre clases, con mayor cantidad de im\u00e1genes en los niveles octa_1 y octa_8, y menor representaci\u00f3n en los octa_2, octa_4 y octa_5.</p> <p></p> <p>Para la divisi\u00f3n del conjunto de datos se utiliz\u00f3 la funci\u00f3n train_test_split de Scikit-learn, aplicando una proporci\u00f3n 80/20 con estratificaci\u00f3n por clase, a fin de mantener la representatividad de cada categor\u00eda:</p> <p></p> <p>De esta manera, el 80 % de las im\u00e1genes se destin\u00f3 al entrenamiento y el 20 % restante a la validaci\u00f3n, garantizando una evaluaci\u00f3n equilibrada y coherente del desempe\u00f1o del modelo.</p> <p>El dataset se encuentra disponible en las siguientes ubicaciones del proyecto:</p> <ul> <li> <p>\ud83d\udce6 GitHub: Equipo-4-PP2-ASTRONOMICA-2C-2025 / 01.Data / 02.Processed / 05.Etiquetado_Final</p> </li> <li> <p>\u2601\ufe0f Google Drive: Carpeta 0.6 Dataset \u2192 05.Etiquetado_Final</p> </li> </ul> <p>Manejo del Desbalance de Clases</p> <p>El conjunto de datos present\u00f3 una distribuci\u00f3n desigual entre algunas categor\u00edas. Para mitigar este desbalance y mejorar la capacidad del modelo para reconocer todos los niveles de nubosidad, se aplicaron tres estrategias complementarias:</p> <ol> <li>C\u00e1lculo de Pesos de Clase:    Se utilizaron pesos generados mediante la funci\u00f3n compute_class_weight de Scikit-learn, con el par\u00e1metro class_weight='balanced'.    Estos valores se integraron a la funci\u00f3n de p\u00e9rdida, otorgando mayor penalizaci\u00f3n a los errores en clases minoritarias, favoreciendo as\u00ed un aprendizaje m\u00e1s equitativo.  </li> <li>Oversampling Din\u00e1mico:    En el conjunto de entrenamiento se implement\u00f3 un sobreremuestreo selectivo de las clases con menor cantidad de muestras, duplicando im\u00e1genes de esas categor\u00edas para equilibrar la exposici\u00f3n del modelo durante el entrenamiento.  </li> <li>Focal Loss:    Se implementa y utiliza una funci\u00f3n de p\u00e9rdida llamada\u00a0FocalLoss, que est\u00e1 dise\u00f1ada para dar m\u00e1s importancia a los ejemplos dif\u00edciles de clasificar, lo cual es com\u00fan en clases minoritarias. Adem\u00e1s, esta implementaci\u00f3n de\u00a0FocalLoss\u00a0tambi\u00e9n incorpora los pesos de clase calculados.</li> </ol> <p>Estas estrategias combinadas permitieron reducir el sesgo hacia las clases mayoritarias y mejorar la capacidad del modelo para generalizar en condiciones atmosf\u00e9ricas menos frecuentes.</p> <p>Transformaciones y Aumento de Datos</p> <p>Con el objetivo de mejorar la capacidad de generalizaci\u00f3n del modelo y reducir el sobreajuste, se aplicaron diversas transformaciones al conjunto de entrenamiento mediante las funciones del m\u00f3dulo torchvision.transforms.</p> <p>Las operaciones incluyeron rotaciones aleatorias (hasta 40\u00b0), volteos horizontales, ajustes de brillo y contraste, traslaciones, cizallamientos y simulaci\u00f3n de zoom mediante recorte y reescalado. Tambi\u00e9n se incorpor\u00f3 desenfoque gaussiano para aumentar la variabilidad visual.</p> <p>Las im\u00e1genes fueron redimensionadas a 224\u00d7224 p\u00edxeles y estandarizadas utilizando la media y desviaci\u00f3n est\u00e1ndar del dataset ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), lo que garantiza la compatibilidad con la arquitectura EfficientNet-B0 preentrenada.</p> <p>Estas t\u00e9cnicas permitieron ampliar artificialmente el conjunto de entrenamiento, generando variaciones realistas que refuerzan la robustez del modelo ante cambios de iluminaci\u00f3n, orientaci\u00f3n y condiciones atmosf\u00e9ricas.</p> <p>Arquitectura del Modelo</p> <p>El modelo implementado se basa en la arquitectura EfficientNet-B0, preentrenada en el dataset ImageNet. Se opt\u00f3 por habilitar el fine-tuning completo, descongelando todas las capas del modelo (param.requires_grad \\= True) para permitir la actualizaci\u00f3n de pesos durante el entrenamiento y adaptar la red completamente al conjunto de im\u00e1genes del proyecto.</p> <p>En cuanto a la estructura de salida, se mantuvo el clasificador original de EfficientNet, reemplazando \u00fanicamente su \u00faltima capa Linear por una nueva adaptada a la tarea de clasificaci\u00f3n de nueve clases (octas 0-8). La cabeza del modelo consta de una capa Dropout con una probabilidad de desactivaci\u00f3n de 0.2 (valor determinado tras m\u00faltiples pruebas), seguida de una capa lineal con 9 neuronas, correspondientes a las 9 categor\u00edas del problema. El tama\u00f1o de entrada del modelo corresponde a tensores de (3, 224, 224), representando im\u00e1genes RGB redimensionadas a 224\u00d7224 p\u00edxeles. El modelo se realiz\u00f3 en entorno local con soporte GPU, utilizando el framework PyTorch.</p> <p>Para el entrenamiento se emple\u00f3 el optimizador Adam con una tasa de aprendizaje de 1e-5 y un weight_decay de 1e-4. El tama\u00f1o de lote fue de 64 im\u00e1genes, configur\u00e1ndose un m\u00e1ximo de 150 \u00e9pocas y aplicando Early Stopping (paciencia \\= 8) para interrumpir el proceso cuando la p\u00e9rdida de validaci\u00f3n dej\u00f3 de mejorar.</p> <p>Funci\u00f3n de P\u00e9rdida y Optimizador</p> <p>Para el entrenamiento del modelo se implement\u00f3 una versi\u00f3n personalizada de la Focal Loss, definida como una clase propia dentro del script. Esta funci\u00f3n reemplaza la entrop\u00eda cruzada est\u00e1ndar y est\u00e1 dise\u00f1ada para dar mayor peso a los ejemplos dif\u00edciles de clasificar, especialmente a las clases minoritarias. La implementaci\u00f3n incorpor\u00f3 expl\u00edcitamente los pesos de clase (class_weights_tensor) calculados previamente, integrados mediante nn.CrossEntropyLoss(weight=class_weights_tensor), lo que permiti\u00f3 penalizar con mayor severidad los errores en categor\u00edas menos representadas. El optimizador utilizado fue Adam, configurado con una tasa de aprendizaje (lr) de 1e-5 y un weight_decay de 1e-4, logrando una convergencia estable durante el fine-tuning. Adem\u00e1s, se implement\u00f3 un scheduler din\u00e1mico (ReduceLROnPlateau), que redujo la tasa de aprendizaje a la mitad (factor=0.5) cuando la p\u00e9rdida de validaci\u00f3n (val_loss) no mejor\u00f3 en un lapso de cinco \u00e9pocas consecutivas (patience=5).</p> <p>Durante el entrenamiento se monitorizaron las m\u00e9tricas de p\u00e9rdida (loss) y precisi\u00f3n (accuracy) por \u00e9poca. El criterio de Early Stopping y de guardado del mejor modelo fue la p\u00e9rdida en validaci\u00f3n, deteni\u00e9ndose el proceso si no se observaban mejoras en val_loss tras ocho \u00e9pocas.</p> <p>Proceso de Entrenamiento</p> <p>El modelo EfficientNet-B0 fue configurado para un m\u00e1ximo de 150 \u00e9pocas, aunque el entrenamiento se detuvo anticipadamente en la \u00e9poca 80 gracias al mecanismo de Early Stopping, al no observarse mejoras en la p\u00e9rdida de validaci\u00f3n (val_loss) durante las \u00faltimas iteraciones.</p> <p>Los resultados finales obtenidos fueron los siguientes:</p> M\u00e9trica Entrenamiento Validaci\u00f3n Loss 0.135154 0.271047 Accuracy 0.749769 (\\~75.0%) 0.676471 (\\~67.6%) <p>Durante la ejecuci\u00f3n, las m\u00e9tricas de rendimiento se registraron mediante tres mecanismos complementarios:</p> <ul> <li> <p>Archivo CSV: se almacen\u00f3 el historial completo de loss, val_loss, accuracy y val_accuracy por \u00e9poca en historial_entrenamiento.csv.</p> </li> <li> <p>Visualizaci\u00f3n Gr\u00e1fica: se gener\u00f3 el archivo grafico_aprendizaje_octas.png, que muestra la evoluci\u00f3n de las curvas de aprendizaje.</p> </li> <li> <p>Consola: las m\u00e9tricas fueron impresas en tiempo real durante el proceso de entrenamiento.</p> </li> </ul> <p>El ciclo de entrenamiento se implement\u00f3 en PyTorch mediante un bucle cl\u00e1sico for epoch in range(num_epochs): que ejecutaba al final de cada \u00e9poca un ciclo completo de validaci\u00f3n seguido de la actualizaci\u00f3n del scheduler con scheduler.step(val_loss).</p> <p>El modelo se guard\u00f3 autom\u00e1ticamente mediante torch.save() cada vez que alcanzaba un nuevo m\u00ednimo de p\u00e9rdida de validaci\u00f3n, asegurando la conservaci\u00f3n de la mejor versi\u00f3n entrenada.</p> <p>El entrenamiento se realiz\u00f3 en un entorno local con GPU compatible con CUDA, lo que permiti\u00f3 optimizar significativamente los tiempos de c\u00f3mputo y aprovechar el fine-tuning completo del modelo.</p> <p>Evaluaci\u00f3n del Modelo</p> <p>La evaluaci\u00f3n del modelo se realiz\u00f3 sobre el conjunto de validaci\u00f3n tras 80 \u00e9pocas de entrenamiento. El an\u00e1lisis se centr\u00f3 en cuatro aspectos principales: matriz de confusi\u00f3n, m\u00e9tricas por clase, m\u00e9tricas globales y registro de errores de predicci\u00f3n.</p> <p>Matriz de Confusi\u00f3n Se gener\u00f3 una matriz de confusi\u00f3n que permiti\u00f3 visualizar la distribuci\u00f3n de aciertos y errores por clase. Los resultados muestran un comportamiento s\u00f3lido en las clases extremas \u2014octa 0 (cielo despejado) y octa 8 (cielo cubierto)\u2014, pero revelan confusiones sistem\u00e1ticas entre clases vecinas.</p> <p>Las principales discrepancias observadas fueron:</p> <ul> <li> <p>43 casos donde im\u00e1genes de clase real 6 fueron clasificadas como clase 5.</p> </li> <li> <p>25 casos de clase real 8 predichas como clase 7.</p> </li> <li> <p>21 casos de clase real 1 predichas como clase 2.</p> </li> </ul> <p>Este comportamiento indica que el modelo tiende a \u201cconfundirse con el vecino\u201d, especialmente en las transiciones graduales de nubosidad. La clase 6 present\u00f3 el peor rendimiento: solo 18 aciertos correctos frente a 43 errores hacia clase 5.</p> <p></p> <p>M\u00e9tricas por Clase</p> <p>Las m\u00e9tricas de precisi\u00f3n, recall y f1-score se calcularon con la funci\u00f3n precision_recall_fscore_support de Scikit-learn y se guardaron en el archivo metricas_modelo_octas.csv. El modelo alcanz\u00f3 los mejores resultados en las clases extremas:</p> <ul> <li> <p>Clase 0 (Despejado): F1-score de 87.5%.</p> </li> <li> <p>Clase 8 (Cubierto): F1-score de 82.7%.</p> </li> <li> <p>Clase 5: presenta la menor precisi\u00f3n del conjunto, con un 42.5%. Esto significa que cuando el modelo predice \"octa 5\", se equivoca m\u00e1s de la mitad de las veces, lo que la convierte en una predicci\u00f3n poco fiable.  </p> </li> <li> <p>Clase 6: Es la categor\u00eda que present\u00f3 mayores dificultades de recuperaci\u00f3n, con un Recall de 21.6%. Esto indica que el modelo no pudo identificar correctamente a casi 4 de cada 5 im\u00e1genes que realmente pertenec\u00edan a esta clase.</p> </li> </ul> <p>M\u00e9tricas Globales</p> <p>La m\u00e9trica global utilizada fue la Accuracy, con un valor final de 67.6% en el conjunto de validaci\u00f3n. La implementaci\u00f3n de evaluaci\u00f3n se centr\u00f3 exclusivamente en las m\u00e9tricas por clase y la precisi\u00f3n general del modelo.</p> <p>Registro de Predicciones y Errores</p> <p>Para un an\u00e1lisis m\u00e1s detallado del comportamiento del modelo, se export\u00f3 un archivo errores_clasificacion.csv que contiene exclusivamente las predicciones incorrectas. Este registro incluye la ruta de la imagen, la etiqueta real, la predicci\u00f3n err\u00f3nea y la carpeta de origen, lo que permiti\u00f3 examinar patrones de error y tipos de im\u00e1genes problem\u00e1ticas.</p> <p>An\u00e1lisis General</p> <p>El modelo presenta un buen desempe\u00f1o en la detecci\u00f3n de extremos atmosf\u00e9ricos (cielos despejados o totalmente cubiertos), pero dificultades para discriminar niveles intermedios de nubosidad. El entrenamiento fue estable, aunque se observa un ligero sobreajuste, reflejado en la diferencia entre las precisiones de entrenamiento (74.9%) y validaci\u00f3n (67.6%). Las t\u00e9cnicas de aumento de datos y balanceo de clases mejoraron el rendimiento general, aunque no fueron suficientes para compensar la escasez de ejemplos en clases ambiguas. En s\u00edntesis, el modelo constituye una base s\u00f3lida para la clasificaci\u00f3n de nubosidad en im\u00e1genes del cielo, pero requiere ajustes adicionales (como incremento de datos en clases intermedias o exploraci\u00f3n de arquitecturas alternativas) para alcanzar una precisi\u00f3n robusta en contextos operativos.</p> <p>An\u00e1lisis de Errores</p> <p>El modelo muestra un patr\u00f3n consistente de confusi\u00f3n entre clases adyacentes, fen\u00f3meno t\u00edpico en tareas de clasificaci\u00f3n ordinal.</p> <p></p> <p>Las confusiones m\u00e1s frecuentes fueron las siguientes:</p> <ul> <li> <p>Clase 6 \u2192 Clase 5: 43 errores (el m\u00e1s significativo).</p> </li> <li> <p>Clase 8 \u2192 Clase 7: 25 errores.</p> </li> <li> <p>Clase 1 \u2192 Clase 2: 21 errores.</p> </li> <li> <p>Clase 0 \u2192 Clase 1: 13 errores.</p> </li> <li> <p>Clase 3 \u2192 Clase 4: 12 errores.</p> </li> </ul> <p>Este comportamiento indica que el modelo tiende a equivocarse con categor\u00edas vecinas, especialmente en los niveles intermedios de nubosidad. En particular, la clase 6 fue la de peor desempe\u00f1o, con solo 18 aciertos correctos frente a 43 errores hacia la clase 5, lo que evidencia que el modelo no logr\u00f3 aprender caracter\u00edsticas distintivas para ese nivel.</p> <p>Durante la etapa de an\u00e1lisis se generaron varios recursos gr\u00e1ficos que facilitaron la interpretaci\u00f3n de los resultados:</p> <ul> <li> <p>distribucion_clases_octas.png \u2192 muestra la cantidad de im\u00e1genes por clase, evidenciando el desbalance del dataset.</p> </li> <li> <p>matriz_confusion_octas.png \u2192 representa visualmente la distribuci\u00f3n de aciertos y errores entre clases.</p> </li> <li> <p>errores_clasificacion_octas.png \u2192 collage con las primeras 9 im\u00e1genes mal clasificadas, cada una acompa\u00f1ada por su etiqueta real y la predicha.</p> </li> <li> <p>grafico_aprendizaje_octas.png \u2192 curvas de entrenamiento y validaci\u00f3n, utilizadas para verificar estabilidad y convergencia.</p> </li> </ul> <p>Los errores observados se deben principalmente a la alta similitud visual y ambig\u00fcedad entre los niveles intermedios de nubosidad, donde las diferencias son sutiles y dif\u00edciles de distinguir incluso para un observador humano. En particular, las clases 4, 5 y 6 presentan l\u00edmites difusos en t\u00e9rminos visuales, lo que explica la tendencia del modelo a confundirlas. A pesar de las t\u00e9cnicas aplicadas de balanceo y aumento de datos, el modelo no logr\u00f3 aprender de forma robusta las transiciones entre niveles contiguos, manteniendo un ligero sobreajuste que afect\u00f3 su capacidad de generalizaci\u00f3n.</p> <p>Visualizaci\u00f3n del Aprendizaje</p> <p>El proceso de aprendizaje del modelo se registr\u00f3 y visualiz\u00f3 mediante el archivo grafico_aprendizaje_octas.png, que representa las curvas de p\u00e9rdida (Loss) y precisi\u00f3n (Accuracy) tanto en entrenamiento como en validaci\u00f3n a lo largo de las 80 \u00e9pocas.</p> <p> </p> <p>Comportamiento de las curvas</p> <p>El gr\u00e1fico muestra un comportamiento de entrenamiento cl\u00e1sico, en el que el modelo aprende de manera efectiva al inicio y luego comienza a mostrar signos de ligero sobreajuste (overfitting) hacia las \u00faltimas \u00e9pocas.</p> <ul> <li> <p>P\u00e9rdida de entrenamiento (Train Loss): Disminuy\u00f3 de forma continua y pronunciada, alcanzando un valor final de 0.135, lo que indica un aprendizaje estable sobre los datos de entrenamiento.  </p> </li> <li> <p>P\u00e9rdida de validaci\u00f3n (Validation Loss): Descendi\u00f3 significativamente en las primeras etapas del entrenamiento, alcanzando su m\u00ednimo en la \u00e9poca 72 (val_loss \\= 0.261), pero posteriormente se estabiliz\u00f3 y comenz\u00f3 a aumentar levemente.</p> </li> <li> <p>Precisi\u00f3n de entrenamiento (Train Accuracy): Aument\u00f3 de manera sostenida hasta llegar a 74.9% al finalizar la \u00e9poca 80.</p> </li> <li> <p>Precisi\u00f3n de validaci\u00f3n (Validation Accuracy): Mejor\u00f3 en paralelo al inicio, alcanzando su punto m\u00e1ximo en la \u00e9poca 70 (val_accuracy \\= 68.7%), tras lo cual se mantuvo estable sin mayores mejoras.</p> </li> </ul> <p>Las curvas reflejan un buen proceso de convergencia, evidenciando que el modelo logr\u00f3 aprender las caracter\u00edsticas principales del dataset.</p> <p>No obstante, la brecha entre las curvas de entrenamiento y validaci\u00f3n (donde las m\u00e9tricas de validaci\u00f3n se estabilizan mientras las de entrenamiento contin\u00faan mejorando) se\u00f1ala un ligero sobreajuste, indicando que el modelo comenz\u00f3 a especializarse en los datos de entrenamiento en lugar de generalizar de manera \u00f3ptima a nuevos ejemplos.</p> <p>El gr\u00e1fico de aprendizaje fue generado usando los datos del historial de entrenamiento, que tambi\u00e9n fueron exportados al archivo historial_entrenamiento.csv. Este registro contiene los valores de loss, val_loss, accuracy y val_accuracy para cada una de las 80 \u00e9pocas que dur\u00f3 el entrenamiento. El an\u00e1lisis num\u00e9rico confirm\u00f3 que:</p> <ul> <li> <p>La mejor precisi\u00f3n de validaci\u00f3n (68.7%) se obtuvo en la \u00e9poca 70.</p> </li> <li> <p>La menor p\u00e9rdida de validaci\u00f3n (0.261) se registr\u00f3 en la \u00e9poca 72, momento a partir del cual comenz\u00f3 el estancamiento.</p> </li> </ul> <p>Estos resultados justificaron la aplicaci\u00f3n del Early Stopping, que detuvo el entrenamiento en el punto \u00f3ptimo antes de que el sobreajuste se intensificara.</p> <p>Evaluaci\u00f3n Final del Modelo</p> <p>El modelo EfficientNet-B0, reentrenado mediante un proceso de fine-tuning completo sobre las nueve clases de niveles de nubosidad (octas), alcanz\u00f3 una precisi\u00f3n global (accuracy) del 67.6% en el conjunto de validaci\u00f3n. El entrenamiento fue estable y convergente, deteni\u00e9ndose autom\u00e1ticamente en la \u00e9poca 80 gracias al mecanismo de Early Stopping, activado cuando la p\u00e9rdida de validaci\u00f3n dej\u00f3 de mejorar.</p> <p>El rendimiento del modelo presenta el siguiente comportamiento:</p> <ul> <li> <p>Fortalezas:    - Alta eficacia en los extremos atmosf\u00e9ricos (clases 0 y 8).   - Reconocimiento consistente de patrones visuales bien definidos.   - Buen aprovechamiento de los datos contrastantes y balanceados.</p> </li> <li> <p>Debilidades:    - Dificultad para discriminar niveles intermedios de nubosidad (clases 5 y 6).   - Confusi\u00f3n entre categor\u00edas visualmente similares, incluso tras aplicar aumento de datos y Focal Loss.   - Persistencia de ambig\u00fcedad visual intr\u00ednseca entre clases adyacentes.</p> </li> </ul> <p>El historial de entrenamiento refleja un ligero sobreajuste (overfitting). Al finalizar, la precisi\u00f3n de entrenamiento fue de 74.9%, mientras que la de validaci\u00f3n se mantuvo en 67.6%, generando una brecha aproximada del 7%. Este comportamiento indica que el modelo aprendi\u00f3 adecuadamente los patrones del conjunto de entrenamiento, pero perdi\u00f3 parte de su capacidad de generalizaci\u00f3n ante datos nuevos.</p> <p>En conjunto, el modelo logra capturar de manera efectiva los extremos de nubosidad, pero a\u00fan presenta limitaciones en la representaci\u00f3n de los matices intermedios del cielo. A pesar de ello, constituye una base s\u00f3lida para etapas posteriores de refinamiento, tanto en la mejora de la clasificaci\u00f3n por niveles de octas como en su futura integraci\u00f3n dentro del sistema de monitoreo atmosf\u00e9rico automatizado de la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande.</p> <p>Este modelo forma parte del proyecto desarrollado en el marco de Pr\u00e1cticas Profesionalizantes II del Instituto Polit\u00e9cnico Malvinas Argentinas, en colaboraci\u00f3n con la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande (EARG). Su desarrollo representa una etapa clave en la implementaci\u00f3n de sistemas inteligentes de an\u00e1lisis atmosf\u00e9rico, integrando ciencia de datos e inteligencia artificial con fines cient\u00edficos y educativos.</p> <p></p>"},{"location":"Reporte_EfficientNet_B3/","title":"Reporte de modelo EfficientNet_B3","text":"<p>Modelo de Clasificaci\u00f3n de Nubosidad por Nivel de Octas</p> <p>EfficientNet B3</p> <p>OBJETIVO</p> <p>Se desarrolla un modelo dise\u00f1ado para automatizar la clasificaci\u00f3n del nivel de nubosidad en im\u00e1genes astron\u00f3micas, utilizando redes neuronales profundas. El objetivo principal es estimar el nivel de octas (de 0 a 8), lo cual permite optimizar la observaci\u00f3n astron\u00f3mica en la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande, facilitando la selecci\u00f3n de im\u00e1genes \u00fatiles para an\u00e1lisis cient\u00edficos.</p> <p>Para lograr una clasificaci\u00f3n precisa, se utilizar\u00e1 un modelo preentrenado EfficientNet B3, adaptado mediante t\u00e9cnicas de transferencia de aprendizaje. Este enfoque permite aprovechar el conocimiento previo del modelo en tareas de visi\u00f3n por computadora, acelerando el entrenamiento y mejorando la generalizaci\u00f3n en el dominio espec\u00edfico de im\u00e1genes astron\u00f3micas.</p> <p>ALCANCE</p> <p>El modelo desarrollado, entrenado y evaluado debera clasificar im\u00e1genes astron\u00f3micas seg\u00fan el nivel de nubosidad en octas (de 0 a 8). El modelo se enfoca en im\u00e1genes capturadas por la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande, considerando tanto condiciones de iluminaci\u00f3n clara como oscura.</p> <p>El alcance incluye:</p> <ul> <li> <p>Procesamiento y organizaci\u00f3n del dataset, con im\u00e1genes previamente etiquetadas por nivel de octas y tipo de iluminaci\u00f3n.</p> </li> <li> <p>Entrenamiento de un modelo EfficientNet B3 preentrenado, utilizando t\u00e9cnicas de transferencia de aprendizaje para adaptarlo al dominio espec\u00edfico de im\u00e1genes astron\u00f3micas.</p> </li> <li> <p>Aplicaci\u00f3n de t\u00e9cnicas de mejora del entrenamiento, como normalizaci\u00f3n de clases, early stopping y visualizaci\u00f3n de errores.</p> </li> <li> <p>Evaluaci\u00f3n del modelo mediante m\u00e9tricas como precisi\u00f3n, recall, F1-score y matriz de confusi\u00f3n.</p> </li> <li> <p>Generaci\u00f3n de un sistema automatizado capaz de clasificar nuevas im\u00e1genes de forma eficiente y confiable.</p> </li> </ul> <p>PROCEDIMIENTO DE DISE\u00d1O DE MODELO </p> <p>Preparaci\u00f3n del entorno</p> <p>El modelo se configur\u00f3 un entorno de trabajo basado en Python y la biblioteca PyTorch. Se incorporaron librer\u00edas esenciales para el procesamiento de datos (NumPy, Pandas), visualizaci\u00f3n (Matplotlib, Seaborn), manipulaci\u00f3n de im\u00e1genes (PIL), y aprendizaje profundo (torch, torchvision). Adem\u00e1s, se utilizaron herramientas de evaluaci\u00f3n como scikit-learn para el c\u00e1lculo de m\u00e9tricas de rendimiento y balanceo de clases. Esta configuraci\u00f3n permite un flujo de trabajo eficiente para el entrenamiento, validaci\u00f3n y an\u00e1lisis del modelo.</p> <p></p> <p>Verificaci\u00f3n e Instalaci\u00f3n de GPU</p> <p>Para acelerar el entrenamiento del modelo de clasificaci\u00f3n de im\u00e1genes, se verific\u00f3 la disponibilidad de una GPU en el entorno de ejecuci\u00f3n. El uso de GPU permite realizar c\u00e1lculos intensivos de forma m\u00e1s eficiente, reduciendo significativamente los tiempos de entrenamiento. Se utiliz\u00f3 la biblioteca PyTorch, que ofrece soporte nativo para CUDA y se confirm\u00f3 la correcta instalaci\u00f3n mediante comandos como torch.cuda.is_available(). Esta configuraci\u00f3n garantiza un entorno \u00f3ptimo para el procesamiento de im\u00e1genes a gran escala.</p> <p></p> <p>Ruta del Dataset</p> <p>Las im\u00e1genes utilizadas para el entrenamiento y validaci\u00f3n del modelo se encuentran organizadas en carpetas seg\u00fan el nivel de octas y el tipo de iluminaci\u00f3n (clara u oscura). Estas carpetas est\u00e1n almacenadas localmente en una ruta espec\u00edfica del sistema, por ejemplo:</p> <p></p> <p>Cada subcarpeta dentro de esta ruta representa una clase correspondiente a un nivel de nubosidad, desde octa_0 hasta octa_8, permitiendo una carga estructurada y eficiente de los datos mediante PyTorch. Esta organizaci\u00f3n facilita el uso de ImageFolder o la creaci\u00f3n de datasets personalizados para el entrenamiento supervisado del modelo.</p> <p>Carga de Im\u00e1genes y Etiquetas</p> <p>Para preparar el conjunto de datos, se recorren las carpetas almacenadas en la ruta base, donde cada carpeta representa un nivel de nubosidad en octas (por ejemplo, imagenes_clara_octa_0, imagenes_oscura_octa_5, etc.). Se extraen las rutas de las im\u00e1genes v\u00e1lidas (.jpg, .jpeg, .png) y se asigna la etiqueta correspondiente en funci\u00f3n del n\u00famero de octas indicado en el nombre de la carpeta.</p> <p>Este proceso permite construir dos listas: una con las rutas de las im\u00e1genes (image_paths) y otra con sus respectivas etiquetas (octa_labels), que luego se utilizan para dividir el dataset y alimentar el modelo de clasificaci\u00f3n.</p> <p></p> <p>Visualizaci\u00f3n del Balanceo de Clases</p> <p>Luego se genera un gr\u00e1fico para analizar la distribuci\u00f3n de im\u00e1genes por nivel de octas en el dataset. Primero, se utiliza sns.countplot() para contar cu\u00e1ntas im\u00e1genes hay en cada clase (de 0 a 8 octas) y representarlas en un gr\u00e1fico de barras. Luego se configuran el t\u00edtulo y las etiquetas de los ejes para dar claridad a la visualizaci\u00f3n. Finalmente, el gr\u00e1fico se guarda como un archivo PNG (distribucion_clases_octas.png) para su inclusi\u00f3n en el informe. Esta representaci\u00f3n permite identificar si existe un desbalance entre las clases, lo cual es clave para aplicar t\u00e9cnicas de normalizaci\u00f3n durante el entrenamiento.</p> <p></p> <p>El histograma muestra la cantidad de im\u00e1genes disponibles para cada nivel de octas (de 0 a 8). Se puede observar lo siguiente:</p> <ul> <li> <p>Las clases 1 y 8 presentan la mayor cantidad de im\u00e1genes, superando las 450, lo que indica una alta representatividad.</p> </li> <li> <p>Las clases 2, 4 y 5 son las menos representadas, con valores cercanos a 220-280 im\u00e1genes, lo que evidencia un desbalance en el dataset.</p> </li> <li> <p>Las dem\u00e1s clases (0, 3, 6, 7) tienen una distribuci\u00f3n intermedia, entre 350 y 420 im\u00e1genes.</p> </li> </ul> <p>Este desbalance afectar\u00eda el rendimiento del modelo, favoreciendo las clases m\u00e1s frecuentes. Por lo que m\u00e1s adelante ser\u00e1 necesario aplicar t\u00e9cnicas como normalizaci\u00f3n de clases o ponderaci\u00f3n de p\u00e9rdida para mitigar el sesgo y mejorar la precisi\u00f3n en todas las categor\u00edas.</p> <p>Divisi\u00f3n del Dataset en Entrenamiento y Validaci\u00f3n</p> <p>Realizamos la separaci\u00f3n del conjunto de datos en dos partes, 80% para entrenamiento y 20% para validaci\u00f3n. Se utiliza la funci\u00f3n train_test_split de scikit-learn, que divide las listas de rutas de im\u00e1genes (image_paths) y sus etiquetas (octa_labels) en subconjuntos. Se aplica el par\u00e1metro stratify=octa_labels para garantizar que la proporci\u00f3n de clases se mantenga en ambos conjuntos, evitando desbalances entre entrenamiento y validaci\u00f3n. Adem\u00e1s, se fija random_state=42 para asegurar reproducibilidad en la divisi\u00f3n.</p> <p></p> <p>C\u00e1lculo de Pesos de Clase</p> <p>El c\u00e1lculo de los pesos de clase se realiza para compensar el desbalance observado en la distribuci\u00f3n de im\u00e1genes por nivel de octas. Se utiliza la funci\u00f3n compute_class_weight de scikit-learn, que asigna un peso mayor a las clases menos representadas y un peso menor a las clases con m\u00e1s im\u00e1genes. Estos pesos se aplican durante el entrenamiento del modelo en la funci\u00f3n de p\u00e9rdida, con el objetivo de reducir el sesgo hacia las clases mayoritarias y mejorar la precisi\u00f3n global del sistema.</p> <p></p> <p>Detecci\u00f3n de Clases Minoritarias</p> <p>La distribuci\u00f3n de im\u00e1genes por nivel de octas para identificar las clases menos representadas en el dataset. Primero, se calcula la cantidad de im\u00e1genes por clase utilizando value_counts() de pandas. Luego, se determina el promedio de im\u00e1genes entre todas las clases y se seleccionan aquellas que tienen un n\u00famero inferior a este promedio. Finalmente, se imprime la lista de clases minoritarias detectadas. Este an\u00e1lisis es \u00fatil para aplicar estrategias de balanceo, como el uso de pesos de clase o t\u00e9cnicas de aumento de datos, con el fin de mejorar la equidad en el entrenamiento del modelo.</p> <p>Creaci\u00f3n del Dataset Personalizado</p> <p>Se define la clase OctaDataset, que hereda de torch.utils.data.Dataset y permite gestionar las im\u00e1genes y etiquetas de forma flexible. </p> <ul> <li> <p>image_paths y labels: listas con las rutas de las im\u00e1genes y sus etiquetas.</p> </li> <li> <p>img_width y img_height: dimensiones a las que se redimensionar\u00e1n las im\u00e1genes.</p> </li> <li> <p>augment: indica si se aplicar\u00e1n t\u00e9cnicas de aumento de datos.</p> </li> <li> <p>minority_classes: lista de clases minoritarias para aplicar estrategias de balanceo.</p> </li> <li> <p>oversample_factor: factor para replicar im\u00e1genes de clases menos representadas.</p> </li> </ul> <p>Este dise\u00f1o facilita la incorporaci\u00f3n de transformaciones, el manejo de desbalance en las clases y la preparaci\u00f3n de los datos para el entrenamiento del modelo.</p> <p></p> <p>Oversampling Din\u00e1mico</p> <p>Si se detectan clases minoritarias, se recorren todas las etiquetas y por cada imagen perteneciente a una clase poco representada, se duplican sus entradas en el dataset seg\u00fan el valor definido en oversample_factor. Esto significa que las im\u00e1genes de clases minoritarias se agregan varias veces a las listas image_paths y labels, aumentando su presencia en el conjunto de datos. Esta t\u00e9cnica ayuda a equilibrar la distribuci\u00f3n de clases y mejora la capacidad del modelo para aprender patrones en categor\u00edas menos frecuentes.</p> <p></p> <p>Aplicaci\u00f3n de Transformaciones</p> <p>Se define un conjunto de transformaciones para preparar las im\u00e1genes antes de ser utilizadas por el modelo. Se utiliza torchvision.transforms para aplicar dos configuraciones:</p> <ul> <li> <p>Modo con aumento de datos (augment=True): Incluye operaciones como redimensionamiento, volteo horizontal aleatorio, rotaci\u00f3n, ajuste de brillo y contraste, transformaciones afines, recorte aleatorio, desenfoque gaussiano y conversi\u00f3n a tensor. Estas t\u00e9cnicas aumentan la variabilidad del dataset, mejorando la capacidad de generalizaci\u00f3n del modelo.</p> </li> <li> <p>Modo sin aumento (augment=False): Aplica \u00fanicamente el redimensionamiento, conversi\u00f3n a tensor y normalizaci\u00f3n.</p> </li> </ul> <p>En ambos casos, se utiliza la normalizaci\u00f3n con los valores de mean y std predefinidos para modelos entrenados en ImageNet, lo que asegura compatibilidad con arquitecturas como EfficientNet B3.</p> <p></p> <p>M\u00e9todos __len__ y __getitem__</p> <p>En la clase OctaDataset, se implementan dos m\u00e9todos fundamentales para el funcionamiento del dataset personalizado:</p> <ul> <li> <p>__len__: Devuelve el n\u00famero total de im\u00e1genes disponibles en el dataset, utilizando la longitud de la lista image_paths. Esto permite que PyTorch conozca el tama\u00f1o del conjunto de datos.</p> </li> <li> <p>__getitem__: Recupera una imagen y su etiqueta correspondiente seg\u00fan el \u00edndice idx. </p> </li> </ul> <p>El proceso incluye:</p> <ul> <li> <p>Obtener la ruta de la imagen y su etiqueta.</p> </li> <li> <p>Abrir la imagen con PIL y convertirla a formato RGB.</p> </li> <li> <p>Aplicar las transformaciones definidas previamente (aumento de datos o normalizaci\u00f3n).</p> </li> <li> <p>Manejar errores: si ocurre un problema al cargar la imagen, se imprime un mensaje y se devuelve un tensor vac\u00edo con las dimensiones esperadas.</p> </li> </ul> <p>Este dise\u00f1o asegura que cada lote de datos se procese correctamente, incluso si alguna imagen presenta inconvenientes, evitando interrupciones en el entrenamiento.</p> <p></p> <p>Configuraci\u00f3n de Par\u00e1metros y Creaci\u00f3n de DataLoaders</p> <p>En este metodo se definen los par\u00e1metros principales para el entrenamiento del modelo:</p> <ul> <li> <p>img_width, img_height: dimensiones a las que se redimensionar\u00e1n las im\u00e1genes (224 \u00d7 224 p\u00edxeles), compatibles con arquitecturas como EfficientNet.</p> </li> <li> <p>batch_size: tama\u00f1o del lote establecido en 64, lo que permite procesar varias im\u00e1genes en paralelo para optimizar el rendimiento.</p> </li> </ul> <p>Luego, se crean dos instancias del dataset personalizado:</p> <ul> <li> <p>train_dataset: incluye aumento de datos (augment=True) y aplica oversampling para clases minoritarias con un factor de 3.</p> </li> <li> <p>val_dataset: no aplica aumento de datos, asegurando una evaluaci\u00f3n consistente.</p> </li> </ul> <p>Finalmente, se construyen los DataLoaders:</p> <ul> <li> <p>train_loader: carga los datos de entrenamiento en lotes, con barajado aleatorio (shuffle=True) para mejorar la generalizaci\u00f3n.</p> </li> <li> <p>val_loader: carga los datos de validaci\u00f3n sin barajado (shuffle=False) para mantener la consistencia en la evaluaci\u00f3n.</p> </li> </ul> <p>Esta configuraci\u00f3n garantiza un flujo eficiente y balanceado para el entrenamiento y validaci\u00f3n del modelo.</p> <p></p> <p>Definici\u00f3n del Modelo con Fine-Tuning Completo</p> <p>El c\u00f3digo inicializa el modelo EfficientNet B3 preentrenado en el conjunto de datos ImageNet utilizando la funci\u00f3n models.efficientnet_b3(pretrained=True) de torchvision. Las capas del modelo ser\u00e1n entrenadas, permitiendo adaptar completamente la arquitectura al dominio espec\u00edfico de im\u00e1genes astron\u00f3micas. Esta estrategia de fine-tuning completo es \u00fatil cuando se dispone de un dataset suficientemente grande y se busca maximizar la precisi\u00f3n, aunque implica un mayor costo computacional.</p> <p></p> <p>Ajuste del Clasificador para el N\u00famero de Clases</p> <p>El c\u00f3digo modifica la capa final del modelo EfficientNet B3 para adaptarla al problema de clasificaci\u00f3n de nubosidad en 9 clases (niveles de octas de 0 a 8). Esto se logra reemplazando la \u00faltima capa totalmente conectada (nn.Linear) por una nueva que recibe el mismo n\u00famero de caracter\u00edsticas de entrada (in_features) y genera 9 salidas. </p> <p></p> <p>Funci\u00f3n de P\u00e9rdida, Optimizador y Scheduler</p> <p>Para abordar el desbalance de clases y mejorar la robustez del entrenamiento, se implementa la funci\u00f3n de p\u00e9rdida Funci\u00f3n de P\u00e9rdida, que extiende la p\u00e9rdida por entrop\u00eda cruzada. Esta t\u00e9cnica reduce el impacto de las clases mayoritarias y pone mayor \u00e9nfasis en las clases minoritarias mediante dos par\u00e1metros:</p> <ul> <li> <p>alpha: factor de ponderaci\u00f3n para ajustar la importancia global.</p> </li> <li> <p>gamma: controla cu\u00e1nto se penalizan las predicciones f\u00e1ciles, enfocando el aprendizaje en casos dif\u00edciles.</p> </li> </ul> <p>La funci\u00f3n calcula la p\u00e9rdida base con CrossEntropyLoss (incluyendo los pesos de clase) y aplica la f\u00f3rmula de Focal Loss para obtener el valor final.</p> <p>Tambi\u00e9n:</p> <ul> <li> <p>Se utiliza el optimizador Adam con una tasa de aprendizaje inicial de 1e-4 y weight_decay para regularizaci\u00f3n.</p> </li> <li> <p>Se incorpora un scheduler ReduceLROnPlateau, que reduce la tasa de aprendizaje autom\u00e1ticamente cuando la m\u00e9trica de validaci\u00f3n deja de mejorar, evitando estancamientos en el entrenamiento.</p> </li> </ul> <p>Esta configuraci\u00f3n busca maximizar la precisi\u00f3n del modelo y garantizar una convergencia estable.</p> <p></p> <p>Entrenamiento con Early Stopping</p> <p>En el c\u00f3digo se implementa el ciclo de entrenamiento del modelo con la t\u00e9cnica de Early Stopping para evitar el sobreajuste. Se establecen los siguientes par\u00e1metros:</p> <ul> <li> <p>num_epochs \\= 100: n\u00famero m\u00e1ximo de \u00e9pocas.</p> </li> <li> <p>patience \\= 8: n\u00famero de \u00e9pocas consecutivas sin mejora en la p\u00e9rdida de validaci\u00f3n antes de detener el entrenamiento.</p> </li> <li> <p>best_val_loss: inicializado con infinito para registrar la mejor p\u00e9rdida alcanzada.</p> </li> <li> <p>best_model_wts: almacena los pesos del modelo cuando se obtiene la mejor validaci\u00f3n.</p> </li> <li> <p>epochs_no_improve: contador de \u00e9pocas sin mejora.</p> </li> </ul> <p>Durante cada \u00e9poca:</p> <ol> <li> <p>El modelo se pone en modo entrenamiento (model.train()).</p> </li> <li> <p>Se inicializan acumuladores para p\u00e9rdida, aciertos y total de muestras.</p> </li> <li> <p>Se recorren los lotes del train_loader, aplicando: </p> </li> <li> <p>Carga de im\u00e1genes y etiquetas en el dispositivo (GPU).</p> </li> <li> <p>C\u00e1lculo de predicciones y p\u00e9rdida con la funci\u00f3n definida (criterion).</p> </li> <li> <p>Retropropagaci\u00f3n (loss.backward()) y actualizaci\u00f3n de par\u00e1metros (optimizer.step()).</p> </li> <li> <p>Se acumula la p\u00e9rdida y se calcula la precisi\u00f3n en entrenamiento.</p> </li> <li> <p>Se registran las m\u00e9tricas en listas para an\u00e1lisis posterior.</p> </li> </ol> <p>Este enfoque permite monitorear el rendimiento y detener el entrenamiento cuando no hay mejoras significativas, optimizando el tiempo y evitando sobreajuste.</p> <p></p> <p>Validaci\u00f3n del Modelo y Registro de M\u00e9tricas</p> <p>Despu\u00e9s de cada \u00e9poca de entrenamiento, el modelo se eval\u00faa en el conjunto de validaci\u00f3n para medir su rendimiento. El proceso incluye:</p> <ol> <li> <p>Modo evaluaci\u00f3n: Se activa con model.eval() para deshabilitar operaciones como dropout y batch normalization en modo entrenamiento.</p> </li> <li> <p>Desactivaci\u00f3n del c\u00e1lculo de gradientes: Se utiliza torch.no_grad() para reducir el consumo de memoria y acelerar la inferencia.</p> </li> <li> <p>C\u00e1lculo de p\u00e9rdida y precisi\u00f3n: </p> </li> <li> <p>Se recorren los lotes del val_loader.</p> </li> <li> <p>Se calculan las predicciones y la p\u00e9rdida con la misma funci\u00f3n definida (criterion).</p> </li> <li> <p>Se acumulan los valores para obtener la p\u00e9rdida promedio (val_loss) y la precisi\u00f3n (val_acc).</p> </li> <li> <p>Registro hist\u00f3rico: Se guardan las m\u00e9tricas en listas para an\u00e1lisis posterior (val_loss_history, val_acc_history). Archivo historial_entrenamiento.csv</p> </li> <li> <p>Ajuste din\u00e1mico de la tasa de aprendizaje: Se llama al scheduler ReduceLROnPlateau para reducir el learning rate si la p\u00e9rdida de validaci\u00f3n no mejora.</p> </li> <li> <p>Impresi\u00f3n de resultados por \u00e9poca: Se muestra la p\u00e9rdida y precisi\u00f3n tanto en entrenamiento como en validaci\u00f3n, permitiendo monitorear el progreso.</p> </li> </ol> <p>Este enfoque asegura un seguimiento detallado del rendimiento del modelo y facilita la aplicaci\u00f3n de Early Stopping cuando no se observan mejoras significativas.</p> <p></p> <p>Luego en el c\u00f3digo se implementa la l\u00f3gica completa de Early Stopping para detener el entrenamiento cuando no se observa mejora en la p\u00e9rdida de validaci\u00f3n durante un n\u00famero determinado de \u00e9pocas (definido por patience). El flujo es el siguiente:</p> <ol> <li> <p>Comparaci\u00f3n de p\u00e9rdidas: Si la p\u00e9rdida de validaci\u00f3n (val_loss) es menor que la mejor registrada (best_val_loss), se actualizan:</p> </li> <li> <p>best_val_loss con el nuevo valor.</p> </li> <li> <p>best_model_wts con los pesos actuales del modelo.</p> </li> <li> <p>Se guarda el modelo en disco como mejor_modelo_efficientnet_finetuning.pth.</p> </li> <li> <p>Se reinicia el contador epochs_no_improve a cero.</p> </li> <li> <p>Incremento del contador: Si no hay mejora, se incrementa epochs_no_improve.</p> </li> <li> <p>Activaci\u00f3n de Early Stopping: Cuando epochs_no_improve alcanza el valor de patience, se imprime el mensaje \"Early stopping activado\" y se interrumpe el ciclo de entrenamiento.</p> </li> <li> <p>Restauraci\u00f3n del mejor modelo: Al finalizar, se cargan los pesos del mejor modelo registrado para garantizar que se utilice la versi\u00f3n m\u00e1s precisa.</p> </li> </ol> <p>Este mecanismo optimiza el tiempo de entrenamiento y evita el sobreajuste, asegurando que el modelo final sea el m\u00e1s eficiente seg\u00fan la m\u00e9trica de validaci\u00f3n.</p> <p></p> <p>Registro del Historial de Entrenamiento</p> <p>En el c\u00f3digo se crea un DataFrame con las m\u00e9tricas registradas durante el entrenamiento y validaci\u00f3n del modelo, incluyendo:</p> <ul> <li> <p>loss: p\u00e9rdida promedio en el conjunto de entrenamiento.</p> </li> <li> <p>val_loss: p\u00e9rdida promedio en el conjunto de validaci\u00f3n.</p> </li> <li> <p>accuracy: precisi\u00f3n en entrenamiento.</p> </li> <li> <p>val_accuracy: precisi\u00f3n en validaci\u00f3n.</p> </li> </ul> <p>Estas m\u00e9tricas se almacenan en listas durante el ciclo de entrenamiento y luego se consolidan en un archivo CSV llamado historial_entrenamiento.csv. Este registro permite realizar an\u00e1lisis posteriores, generar visualizaciones como curvas de p\u00e9rdida y precisi\u00f3n, tambi\u00e9n documentar el rendimiento del modelo en el informe</p> <p></p> <p></p> <p>Evaluaci\u00f3n del Modelo de Clasificaci\u00f3n de Nubosidad por Nivel de Octa</p> <p>En el siguiente parte del c\u00f3digo est\u00e1 dise\u00f1ado para evaluar el rendimiento de un modelo. Primero, se pone el modelo en modo de evaluaci\u00f3n para desactivar funciones como el dropout, que solo se usan durante el entrenamiento. Luego se recorren las im\u00e1genes del conjunto de validaci\u00f3n sin calcular gradientes, lo que ahorra recursos.</p> <p>Para cada lote de im\u00e1genes, se obtienen las predicciones del modelo y se comparan con las etiquetas verdaderas. Las predicciones y las etiquetas se guardan en listas para analizarlas despu\u00e9s.</p> <p>Una vez que se tienen todas las predicciones, se genera una matriz de confusi\u00f3n que muestra cu\u00e1ntas veces el modelo acert\u00f3 o se equivoc\u00f3 en cada clase. Esta matriz se gr\u00e1fica y se guarda como una imagen en formato PNG.</p> <p>Despu\u00e9s, se calculan m\u00e9tricas de evaluaci\u00f3n por clase: precisi\u00f3n, recall y F1-score. Tambi\u00e9n se calcula la precisi\u00f3n global del modelo. Todos estos resultados se guardan en un archivo CSV, donde cada fila representa una clase de octa y sus m\u00e9tricas, y al final se agrega una fila con la precisi\u00f3n global.</p> <p></p> <p></p> <p></p> <p>Rendimiento global</p> <ul> <li>Exactitud global: 70.28%. El modelo acierta aproximadamente 7 de cada 10 im\u00e1genes, lo cual es aceptable, pero indica espacio para mejora, especialmente en clases intermedias.</li> </ul> <p>Observaciones de la matriz de confusi\u00f3n</p> <ul> <li> <p>Clases bien clasificadas:</p> </li> <li> <p>Clase 0 (octa 0): 67 aciertos, 10 errores \u2192 muy buen desempe\u00f1o.</p> </li> <li> <p>Clase 8 (octa 8): 78 aciertos, 19 errores \u2192 tambi\u00e9n muy s\u00f3lido.     Estas clases extremas (cielo despejado y cielo totalmente cubierto) son m\u00e1s f\u00e1ciles de identificar.</p> </li> <li> <p>Clases con confusi\u00f3n alta:</p> </li> <li> <p>Clase 6: Predicciones dispersas (26 como clase 5, 16 como clase 7).</p> </li> <li> <p>Clase 4 y 5: Se confunden entre s\u00ed y con clase 6.     Esto indica que el modelo tiene dificultad para diferenciar niveles intermedios de nubosidad.</p> </li> <li> <p>Patr\u00f3n general:   La diagonal es dominante, pero hay desplazamientos hacia clases vecinas, lo que sugiere que el modelo entiende la progresi\u00f3n de nubosidad, aunque no con precisi\u00f3n perfecta.</p> </li> </ul> <p>M\u00e9tricas por clase</p> <ul> <li> <p>Mejor precisi\u00f3n: Clase 8 (0.90) y clase 0 (0.89).</p> </li> <li> <p>Peor precisi\u00f3n: Clase 5 (0.50) y clase 7 (0.61).</p> </li> <li> <p>Mejor recall: Clase 0 (0.87) y clase 3 (0.78).</p> </li> <li> <p>Peor recall: Clase 6 (0.42), lo que confirma que el modelo falla en detectar correctamente esta clase.</p> </li> <li> <p>F1-score m\u00e1s bajo: Clase 5 (0.58) y clase 6 (0.52).   Esto indica que las clases intermedias son el punto d\u00e9bil del modelo.</p> </li> </ul> <p>Interpretaci\u00f3n</p> <ul> <li> <p>El modelo es robusto en extremos (cielos despejados y cubiertos), pero d\u00e9bil en nubosidad parcial, donde las diferencias visuales son m\u00e1s sutiles.</p> </li> <li> <p>La confusi\u00f3n entre clases consecutivas sugiere que el modelo capta la tendencia, pero necesita m\u00e1s discriminaci\u00f3n en niveles medios.</p> </li> </ul> <p></p> <p></p> <p>Las im\u00e1genes muestran errores de clasificaci\u00f3n del modelo en niveles intermedios de nubosidad. En todos los casos, la predicci\u00f3n est\u00e1 cerca del valor real, lo que indica que el modelo entiende la tendencia general, pero falla en la discriminaci\u00f3n precisa. Por ejemplo, cuando la etiqueta real es 6, el modelo predice 5; cuando es 1, predice 2; y cuando es 7, predice 6. Esto sugiere que el error m\u00e1s com\u00fan es una desviaci\u00f3n de \u00b11 nivel.</p> <p>Se observa que las im\u00e1genes con iluminaci\u00f3n artificial (bordes amarillos o naranjas, t\u00edpicos de tomas nocturnas) y las que presentan nubes difusas o mezcladas con claros son las m\u00e1s problem\u00e1ticas. Las condiciones de luz y la textura irregular de las nubes parecen influir en la confusi\u00f3n del modelo. No hay errores extremos (como confundir 0 con 8), lo que confirma que el modelo tiene una noci\u00f3n correcta de la progresi\u00f3n de nubosidad.</p> <p>Grafica de aprendizaje de Octas</p> <p></p> <p></p> <p>P\u00e9rdida (Loss) por \u00e9poca</p> <ul> <li> <p>Train Loss: Disminuye de forma continua desde \\~1.3 hasta casi 0.05, lo que indica que el modelo aprende bien en entrenamiento.</p> </li> <li> <p>Validation Loss: Baja r\u00e1pido al inicio (de \\~0.9 a \\~0.35 en las primeras 4 \u00e9pocas), pero luego se estabiliza y oscila entre 0.25 y 0.35.</p> </li> <li> <p>Interpretaci\u00f3n: </p> </li> <li> <p>El hecho de que la p\u00e9rdida de validaci\u00f3n deje de mejorar mientras la de entrenamiento sigue bajando indica sobreajuste a partir de la \u00e9poca 6-7.</p> </li> <li> <p>El modelo memoriza el conjunto de entrenamiento, pero no mejora en generalizaci\u00f3n.</p> </li> </ul> <p>Exactitud (Accuracy) por \u00e9poca</p> <ul> <li> <p>Train Accuracy: Sube de \\~0.32 a \\~0.88, mostrando un aprendizaje fuerte.</p> </li> <li> <p>Validation Accuracy: Mejora r\u00e1pido al inicio (de \\~0.45 a \\~0.68 en las primeras 6 \u00e9pocas), pero luego se estanca cerca de 0.70.</p> </li> <li> <p>Interpretaci\u00f3n: </p> </li> <li> <p>El estancamiento en validaci\u00f3n confirma el sobreajuste.</p> </li> <li> <p>La brecha entre entrenamiento (0.88) y validaci\u00f3n (0.70) al final es significativa.</p> </li> </ul> <p>Resultado - Conclusi\u00f3n</p> <ul> <li> <p>El modelo aprende bien, pero no generaliza \u00f3ptimamente.</p> </li> <li> <p>El sobreajuste comienza alrededor de la \u00e9poca 6-7.</p> </li> <li> <p>Se sugiere realizar entrenamiento con otra versi\u00f3n de modelo pre-entrenado</p> </li> </ul> <p></p>"},{"location":"Reportes/","title":"\ud83e\udde0 Reportes de Modelos de Clasificaci\u00f3n de Nubosidad","text":"<p>Esta secci\u00f3n re\u00fane los informes t\u00e9cnicos de los modelos EfficientNet-B0 y EfficientNet-B3, desarrollados en el marco del proyecto Cielo R\u00edo Grande. Cada reporte documenta el proceso de entrenamiento, validaci\u00f3n y evaluaci\u00f3n de los modelos de clasificaci\u00f3n de nubosidad en im\u00e1genes astron\u00f3micas capturadas por la Estaci\u00f3n Astron\u00f3mica de R\u00edo Grande (EARG).</p>"},{"location":"Reportes/#proposito","title":"Prop\u00f3sito","text":"<p>El objetivo general de estos reportes es analizar el desempe\u00f1o de las arquitecturas EfficientNet en la estimaci\u00f3n del nivel de nubosidad medido en octas (0 a 8). Los modelos buscan automatizar la identificaci\u00f3n del estado del cielo para optimizar las observaciones astron\u00f3micas y fortalecer el monitoreo atmosf\u00e9rico de la estaci\u00f3n.</p>"},{"location":"Reportes/#contenido-de-los-reportes","title":"\ud83d\udcd8 Contenido de los reportes","text":"<ul> <li>Reporte EfficientNet-B0: describe el modelo base, su configuraci\u00f3n de entrenamiento, balanceo de clases, m\u00e9tricas globales y an\u00e1lisis de errores.   Presenta una precisi\u00f3n del 67,6 % en validaci\u00f3n, con buen desempe\u00f1o en cielos despejados o totalmente cubiertos, y dificultades en niveles intermedios de nubosidad:contentReference[oaicite:0]{index=0}.  </li> <li>Reporte EfficientNet-B3: detalla la versi\u00f3n ampliada del modelo con fine-tuning completo, t\u00e9cnicas de normalizaci\u00f3n, aumento de datos y Early Stopping.   Obtiene una precisi\u00f3n global del 70,3 %, mostrando mejor capacidad de discriminaci\u00f3n en clases extremas y un leve sobreajuste en las intermedias:contentReference[oaicite:1]{index=1}.</li> </ul>"},{"location":"Reportes/#alcance","title":"\u2699\ufe0f Alcance","text":"<p>Los reportes incluyen: - Descripci\u00f3n del dataset y su estructura por niveles de octas. - Estrategias de balanceo y aumento de datos. - Configuraci\u00f3n de entrenamiento y validaci\u00f3n. - M\u00e9tricas de desempe\u00f1o (accuracy, precision, recall, F1-score). - An\u00e1lisis de errores y observaciones sobre la generalizaci\u00f3n del modelo. - Visualizaciones de aprendizaje, curvas de p\u00e9rdida y precisi\u00f3n.</p> <p>\ud83d\udd0d Estos documentos constituyen la base de evaluaci\u00f3n comparativa de los modelos de IA del proyecto, y sirven como insumo para futuras iteraciones orientadas a mejorar la precisi\u00f3n en la clasificaci\u00f3n de nubosidad.</p> <p></p>"}]}